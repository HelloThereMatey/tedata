<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.5">
<title>tedata.scraper API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tedata.scraper</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tedata.scraper.find_element_header_match"><code class="name flex">
<span>def <span class="ident">find_element_header_match</span></span>(<span>soup: bs4.BeautifulSoup, selector: str, match_text: str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_element_header_match(soup: BeautifulSoup, selector: str, match_text: str):
    &#34;&#34;&#34;Find .card-header element with text matching search_text&#34;&#34;&#34;
    elements = soup.select(selector)
    print(&#34;Elements found from selector, number of them: &#34;, len(elements))
    for ele in elements:
        print(&#34;\n&#34;, str(ele), &#34;\n&#34;)
        if str(ele.header.text).strip().lower() == match_text.lower():
            print(&#34;Match found: &#34;, ele.header.text)
            return ele
    return None</code></pre>
</details>
<div class="desc"><p>Find .card-header element with text matching search_text</p></div>
</dd>
<dt id="tedata.scraper.scrape_chart"><code class="name flex">
<span>def <span class="ident">scrape_chart</span></span>(<span>url: str = 'https://tradingeconomics.com/united-states/business-confidence',<br>id: str = None,<br>country: str = 'united-states',<br>scraper: <a title="tedata.scraper.TE_Scraper" href="#tedata.scraper.TE_Scraper">TE_Scraper</a> = None,<br>driver: <module 'selenium.webdriver' from '/Users/jamesbishop/Documents/miniconda3/envs/bm/lib/python3.11/site-packages/selenium/webdriver/__init__.py'> = None,<br>headless: bool = True,<br>browser: str = 'firefox') ‑> <a title="tedata.scraper.TE_Scraper" href="#tedata.scraper.TE_Scraper">TE_Scraper</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrape_chart(url: str = &#34;https://tradingeconomics.com/united-states/business-confidence&#34;, 
                 id: str = None,
                 country: str = &#34;united-states&#34;,
                 scraper: TE_Scraper = None,
                 driver: webdriver = None, 
                 headless: bool = True, 
                 browser: str = &#39;firefox&#39;) -&gt; TE_Scraper:
    
    &#34;&#34;&#34; This convenience function will scrape a chart from Trading Economics and return a TE_Scraper object with the series data in
    the &#39;series&#39; attribute. Metadata is also retreived and stored in the &#39;series_metadata&#39; &amp; &#39;metadata&#39; attributes.
    
    *There are multiple ways to use this function:*

    - Supply URL of the chart to scrape OR supply country + id of the chart to scrape. country and id are just the latter parts of the 
    full chart URL. e.g for URL: &#39;https://tradingeconomics.com/united-states/business-confidence&#39;, we could instead use country=&#39;united-states&#39; 
    and id=&#39;business-confidence&#39;. You can supply only id and default country is &#39;united-states&#39;.
    - You can leave scraper and driver as None and the function will create a new TE_Scraper object for that URL and use it to scrape the data.
    You can however save time by passing either a scraper object or a driver object to the function. Best to pass a driver object
    for fastest results.
    
    **Parameters**

    - url (str): The URL of the chart to scrape.
    - id (str): The id of the chart to scrape. This is the latter part of the URL after the country name.
    - country (str): The country of the chart to scrape. Default is &#39;united-states&#39;.
    - scraper (TE_Scraper): A TE_Scraper object to use for scraping the data. If this is passed, the function will not create a new one.
    - driver (webdriver): A Selenium WebDriver object to use for scraping the data. If this is passed, the function will not create a new one. If 
    scraper and driver are both passed, the webdriver of the scraper object will be used rather than the supplied webdriver.
    - headless (bool): Whether to run the browser in headless mode (display no window).
    - browser (str): The browser to use, either &#39;chrome&#39; or &#39;firefox&#39;. Default is &#39;firefox&#39;. Only firefox is supported at the moment (v0.2.0).

    **Returns**
    - TE_Scraper object with the scraped data or None if an error occurs.
    &#34;&#34;&#34;

    if scraper is not None:       #Initialize TE_Scraper object..
        sel = scraper
        if driver is None:
            driver = scraper.driver
        else:
            scraper.driver = driver
    else:
        sel = TE_Scraper(driver = driver, browser = browser, headless = headless, use_existing_driver=True)

    if id is not None:   #Use country and id to create the URL if URL not supplied.
        url = f&#34;https://tradingeconomics.com/{country}/{id}&#34;

    logger.info(f&#34;scrape_chart function: Scraping chart at: {url}, time: {datetime.datetime.now()}&#34;)
    if sel.load_page(url):  # Load the page...
        pass
    else:
        print(&#34;Error loading page at: &#34;, url)
        logger.debug(f&#34;Error loading page at: {url}&#34;)
        return None

    try: #Create the x_index for the series. This is the most complicated bit.
        sel.make_x_index(force_rerun_xlims = True, force_rerun_freqdet = True)  
    except Exception as e:
        print(&#34;Error with the x-axis scraping &amp; frequency deterination using Selenium and tooltips:&#34;, str(e))
        logger.debug(f&#34;Error with the x-axis scraping &amp; frequency deterination using Selenium and tooltips: {str(e)}&#34;)
        return None

    try:  #Scrape the y-axis values from the chart.
        sel.get_y_axis(set_global_y_axis=True)
        #print(&#34;Successfully scraped y-axis values from the chart:&#34;, &#34; \n&#34;, yaxis) 
        logger.debug(f&#34;Successfully scraped y-axis values from the chart.&#34;) 
    except Exception as e:
        print(f&#34;Error scraping y-axis: {str(e)}&#34;)
        logger.debug(f&#34;Error scraping y-axis: {str(e)}&#34;)
        return None
    
    try:
        sel.series_from_chart_soup(set_max_datespan=True)  #Get the series data from path element on the svg chart.
        logger.debug(&#34;Successfully scraped full series path element.&#34;)
    except Exception as e:
        print(&#34;Error scraping full series: &#34;, str(e))
        logger.debug(f&#34;Error scraping full series: {str(e)}&#34;)
        return None

    try: 
        sel.apply_x_index()  ## Apply the x_index to the series, this will resample the data to the frequency of the x_index.
        logger.debug(&#34;Successfully applied x_index scaling to series.&#34;)
    except Exception as e:
        print(f&#34;Error applying x-axis scaling: {str(e)}&#34;)
        logger.debug(f&#34;Error applying x-axis scaling: {str(e)}&#34;)
        return None

    try:  
        scaled_series = sel.scale_series()   ## This converts the pixel co-ordinates to data values.
        if scaled_series is not None:
            logger.info(&#34;Successfully scaled series.&#34;)
    except Exception as e:
        print(f&#34;Error scaling series: {str(e)}&#34;)
        logger.debug(f&#34;Error scaling series: {str(e)}&#34;)
    
    logger.info(f&#34;Successfully scraped time-series from chart at:  {url}, now getting some metadata...&#34;)

    try: 
        sel.scrape_metadata()  # Get metadata from various elements on the page that contain information about the series.
        print(f&#34;Got metadata. \n\nSeries tail: {sel.series.tail()} \n\nScraping complete! Happy pirating yo!&#34;)
        logger.debug(f&#34;Scraping complete, data series retrieved successfully from chart at: {url}&#34;)
        return sel
    except Exception as e:
        print(f&#34;Error scraping chart at: {url}, {str(e)}&#34;) 
        return None</code></pre>
</details>
<div class="desc"><p>This convenience function will scrape a chart from Trading Economics and return a TE_Scraper object with the series data in
the 'series' attribute. Metadata is also retreived and stored in the 'series_metadata' &amp; 'metadata' attributes.</p>
<p><em>There are multiple ways to use this function:</em></p>
<ul>
<li>Supply URL of the chart to scrape OR supply country + id of the chart to scrape. country and id are just the latter parts of the
full chart URL. e.g for URL: 'https://tradingeconomics.com/united-states/business-confidence', we could instead use country='united-states'
and id='business-confidence'. You can supply only id and default country is 'united-states'.</li>
<li>You can leave scraper and driver as None and the function will create a new TE_Scraper object for that URL and use it to scrape the data.
You can however save time by passing either a scraper object or a driver object to the function. Best to pass a driver object
for fastest results.</li>
</ul>
<p><strong>Parameters</strong></p>
<ul>
<li>url (str): The URL of the chart to scrape.</li>
<li>id (str): The id of the chart to scrape. This is the latter part of the URL after the country name.</li>
<li>country (str): The country of the chart to scrape. Default is 'united-states'.</li>
<li>scraper (TE_Scraper): A TE_Scraper object to use for scraping the data. If this is passed, the function will not create a new one.</li>
<li>driver (webdriver): A Selenium WebDriver object to use for scraping the data. If this is passed, the function will not create a new one. If
scraper and driver are both passed, the webdriver of the scraper object will be used rather than the supplied webdriver.</li>
<li>headless (bool): Whether to run the browser in headless mode (display no window).</li>
<li>browser (str): The browser to use, either 'chrome' or 'firefox'. Default is 'firefox'. Only firefox is supported at the moment (v0.2.0).</li>
</ul>
<p><strong>Returns</strong>
- TE_Scraper object with the scraped data or None if an error occurs.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tedata.scraper.TE_Scraper"><code class="flex name class">
<span>class <span class="ident">TE_Scraper</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TE_Scraper(Generic_Webdriver, SharedWebDriverState):
    &#34;&#34;&#34;Class for scraping data from Trading Economics website. This is the main workhorse of the module.
    It is designed to scrape data from the Trading Economics website using Selenium and BeautifulSoup.
    It can load a page, click buttons, extract data from elements, and plot the extracted data. Uses multiple inheritance
    from the Generic_Webdriver and SharedWebDriverState classes. This enables creation of TooltipScraper child classes that have 
    synced atributes such as &#34;chart_soup&#34;, &#34;chart_type&#34; &amp; &#34;date_span&#34; &amp; share the same webdriver object. This is useful for scraping.

    **Init Parameters:** 
    - **kwargs (dict): Keyword  arguments to pass to the Generic_Webdriver class. These are the same as the Generic_Webdriver class.
    These are:
        - driver (webdriver): A Selenium WebDriver object, can put in an active one or make a new one for a new URL.
        - use_existing_driver (bool): Whether to use an existing driver in the namespace. If True, the driver parameter is ignored. Default is False.
        - browser (str): The browser to use for scraping, either &#39;chrome&#39; or &#39;firefox&#39;.
        - headless (bool): Whether to run the browser in headless mode (show no window).
    &#34;&#34;&#34;

    # Define browser type with allowed values
    BrowserType = Literal[&#34;chrome&#34;, &#34;firefox&#34;]  #Chrome still not working as of v0.2.0..
    def __init__(self, **kwargs):
        Generic_Webdriver.__init__(self, **kwargs)
        SharedWebDriverState.__init__(self)
        self.observers.append(self)  # Register self as observer
        self._shared_state = self  # Since we inherit SharedWebDriverState, we are our own shared state

    def load_page(self, url, wait_time=2):
        &#34;&#34;&#34;Load page and wait for it to be ready&#34;&#34;&#34;

        self.last_url = url
        self.series_name = url.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;)
        try:
            self.driver.get(url)
            #logger.debug(f&#34;Page loaded successfully: {url}&#34;)
            logger.info(f&#34;WebPage at {url} loaded successfully.&#34;)
            time.sleep(wait_time)  # Basic wait for page load
            self.full_page = self.get_page_source()
            self.page_soup = BeautifulSoup(self.full_page, &#39;html.parser&#39;)
            self.chart_soup = self.page_soup.select_one(&#34;#chart&#34;)  #Make a bs4 object from the #chart element of the page.
            self.full_chart = self.chart_soup.contents
            self.create_chart_types_dict() # Create the chart types dictionary for the chart.
            return True
        except Exception as e:
            print(f&#34;Error loading page: {str(e)}&#34;)
            logger.debug(f&#34;Error loading page: {str(e)}&#34;)
            return False
    
    def click_button(self, selector, selector_type=By.CSS_SELECTOR):
        &#34;&#34;&#34;Click button using webdriver and wait for response.
        
        **Parameters:**
        - selector (str): The CSS selector for the button to click.
        - selector_type (By): The type of selector to use, By.CSS_SELECTOR by default.&#34;&#34;&#34;

        try:
            # Wait for element to be clickable
            button = self.wait.until(
                EC.element_to_be_clickable((selector_type, selector))
            )
            # Scroll element into view
            time.sleep(0.25)  # Brief pause after scroll
            button.click()
            time.sleep(0.75)
            return True
        except TimeoutException:
            logger.info(f&#34;Button not found or not clickable: {selector}&#34;)
            return False
        except Exception as e:
            logger.info(f&#34;Error clicking button: {str(e)}&#34;)
            return False

    def find_max_button(self, selector: str = &#34;#dateSpansDiv&#34;):
        &#34;&#34;&#34;Find the button on the chart that selects the maximum date range and return the CSS selector for it.
        The button is usually labelled &#39;MAX&#39; and is used to select the maximum date range for the chart. The selector for the button is
        usually &#39;#dateSpansDiv&#39; but can be changed if the button is not found. The method will return the CSS selector for the button.
        This will also create an atrribute &#39;date_spans&#39; which is a dictionary containing the text of the date span buttons and their CSS selectors.&#34;&#34;&#34;

        try:
            buts = self.page_soup.select_one(selector)
            datebut = buts[0] if isinstance(buts, list) else buts
            self.date_spans = {child.text: f&#34;a.{child[&#39;class&#39;][0] if isinstance(child[&#39;class&#39;], list) else child[&#39;class&#39;]}:nth-child({i+1})&#34; for i, child in enumerate(datebut.children)}

            if &#34;MAX&#34; in self.date_spans.keys():
                max_selector = self.date_spans[&#34;MAX&#34;]
            else:
                raise ValueError(&#34;MAX button not found.&#34;)
            logger.debug(f&#34;MAX button found for chart at URL: {self.last_url}, selector: {max_selector}&#34;)
            
            return max_selector
        except Exception as e:
            print(f&#34;Error finding date spans buttons: {str(e)}&#34;)
            logger.debug(f&#34;Error finding date spans buttons: {str(e)}&#34;)
            return None
    
    def click_max_button(self):
        &#34;&#34;&#34;Click the button that selects the maximum date range on the chart. This is usually the &#39;MAX&#39; button and is used to select the maximum date range for the chart.
        The method will find the button and click it. It will also wait for the chart to update after clicking the button.&#34;&#34;&#34;
        max_selector = self.find_max_button()
        if self.click_button(max_selector):
            time.sleep(1)
            logger.info(&#34;MAX button clicked successfully.&#34;)
            self.date_span = &#34;MAX&#34;
            self.update_chart()
        else:
            logger.debug(&#34;Error clicking MAX button.&#34;)
            return False
        
    def determine_date_span(self, update_chart: bool = True):
        &#34;&#34;&#34;Determine the selected date span from the Trading Economics chart currently displayed in webdriver.&#34;&#34;&#34;

        if update_chart: 
            self.update_chart()
        ## Populate the date spans dictionary
        buts = self.chart_soup.select(&#34;#dateSpansDiv&#34;)
        datebut = buts[0] if isinstance(buts, list) else buts
        self.date_spans = OrderedDict()
        for i, child in enumerate(datebut.children):
            selector = f&#34;a.{child[&#39;class&#39;][0] if isinstance(child[&#39;class&#39;], list) else child[&#39;class&#39;]}:nth-child({i+1})&#34;
            self.date_spans[child.text] = selector

        ## Find the selected date span
        if len(buts) == 1:
            result = buts[0].children
        elif len(buts) &gt; 1:
            print(&#34;Multiple date spans found&#34;)
            return buts
        else:
            print(&#34;No date spans found&#34;)
            return None

        for r in result:
            #print(&#34;Date span element: &#34;, r)
            if &#34;selected&#34;in r[&#34;class&#34;]:
                date_span = {r.text: r}
                return date_span
            else:
                return None

    def update_chart(self):
        &#34;&#34;&#34;Update the chart attributes after loading a new page or clicking a button. This will check the page source and update the 
        beautiful soup objects such as chart_soup, from which most other methods derive their functionality. It will also update the full_chart attribute
        which is the full HTML of the chart element on the page. This method should be run after changing something on the webpage via driver such
        as clicking a button to change the date span or chart type.&#34;&#34;&#34;

        try:
            # Since we inherit from SharedWebDriverState, we can directly set the page_source property
            self.page_source = self.driver.page_source
            return True

        except Exception as e:
            logger.error(f&#34;Failed to update chart: {e}&#34;)
            return False

    def set_date_span(self, date_span: str):
        &#34;&#34;&#34;Set the date span on the Trading Economics chart. This is done by clicking the date span button on the chart. The date span is a button on the chart
        that allows you to change the date range of the chart. This method will click the button for the date span specified in the date_span parameter.
        The date_span parameter should be a string that matches one of the date span buttons on the chart. The method will also update the date_span attribute
        of the class to reflect the new date span.&#34;&#34;&#34;
        if not hasattr(self, &#34;date_spans&#34;):
            self.determine_date_span()
        if date_span in self.date_spans.keys():
            if self.click_button(self.date_spans[date_span]):
                self.date_span = date_span
                logger.info(f&#34;Date span set to: {date_span}&#34;)
                self.update_chart()
                return True
            else:
                logger.info(f&#34;Error setting date span: {date_span}, check that the date span button is clickable.&#34;)
                return False
        else:
            logger.info(f&#34;Error setting date span: {date_span}, check that the supplied date span matches one of the keys in the self.date_spans attribute (dict).&#34;)
            return False

    def update_date_span(self, update_chart: bool = False):
        &#34;&#34;&#34;Update the date span after clicking a button. This will check the page source and update the date span attribute.
        This method can be used t check that the curret date span is correct after clicking a button to change it. 
        It will update the date_span attribute. It is not necessary after running set_date_span though as that method already updates the date span attribute.

        **Parameters:**
        - update_chart (bool): Whether to update the chart before determining the date span. Default is False.
        &#34;&#34;&#34;

        if update_chart:
            self.update_chart()
        self.date_span_dict = self.determine_date_span()
        self.date_span = list(self.date_span_dict.keys())[0]
    
    def create_chart_types_dict(self):
        &#34;&#34;&#34;Create a dictionary of chart types and their CSS selectors. This is used to select the chart type on the Trading Economics chart.
        The dictionary is stored in the chart_types attribute of the class. The keys are the names of the chart types and the values are the CSS selectors
        for the chart type buttons on the chart.&#34;&#34;&#34;

        hart_types = self.chart_soup.select_one(&#34;#chart &gt; div &gt; div &gt; div.hawk-header &gt; div &gt; div.pickChartTypes &gt; div &gt; div&#34;)
        self.chart_types = {child[&#34;title&#34;]: &#34;.&#34;+child[&#34;class&#34;][0]+&#34; .&#34;+ child.button[&#34;class&#34;][0] for child in hart_types.children}
        self.expected_types = {chart_type: self.chart_types[chart_type].split(&#34; &#34;)[0].replace(&#34;.&#34;, &#39;&#39;) for chart_type in self.chart_types.keys()}
        logger.info(f&#34;Chart types dictionary created successfully: {self.chart_types.keys()}&#34;)

    def select_line_chart(self, update_chart: bool = False):
        &#34;&#34;&#34;Select the line chart type on the Trading Economics chart. This is done by clicking the chart type button and then selecting the line chart type.&#34;&#34;&#34;

        if update_chart:
            self.update_chart()
        if not hasattr(self, &#34;chart_types&#34;):
            self.create_chart_types_dict()

        if self.click_button(&#34;#chart &gt; div &gt; div &gt; div.hawk-header &gt; div &gt; div.pickChartTypes &gt; div &gt; button&#34;):
            if self.click_button(self.chart_types[&#34;Line&#34;]):
                self.chart_type = &#34;lineChart&#34;
                logger.info(&#34;Line chart type selected.&#34;)
                self.update_chart()
                return True
        else:
            print(&#34;Error selecting line chart type.&#34;)
            logger.debug(&#34;Error selecting line chart type.&#34;)
            return None
    
    def select_chart_type(self, chart_type: str):
        &#34;&#34;&#34;Select a chart type on the Trading Economics chart. This is done by clicking the chart type button and then selecting the specified chart type.
        The chart type should be a string that matches one of the chart types in the chart_types dictionary. The method will click the chart type button
        and then select the specified chart type. It will also update the chart_type attribute of the class to reflect the new chart type.

        **Parameters:**
        - chart_type (str): The chart type to select on the chart. This must be one of the keys of the chart_types dictionary attribute of the class.
        List the options by printing self.chart_types.keys()
        &#34;&#34;&#34;
        if not hasattr(self, &#34;chart_types&#34;):
            self.create_chart_types_dict()

        if chart_type in self.chart_types.keys():
            if self.click_button(&#34;#chart &gt; div &gt; div &gt; div.hawk-header &gt; div &gt; div.pickChartTypes &gt; div &gt; button&#34;):
                self.click_button(self.chart_types[chart_type])
                self.chart_type = self.expected_types[chart_type]
                logger.info(f&#34;Chart type set to: {chart_type}&#34;)
                self.update_chart()
                return True
            else:
                logger.debug(f&#34;Error selecting chart type: {chart_type}&#34;)
                return False
        else:
            logger.debug(f&#34;Chart type not found: {chart_type}&#34;)
            return False

    ## Determine chart type from the chart displayed in the webdriver. This is not working yet,
    # the buttons are not easi;y distinguishable, leave for now. chart_type will have to bve remembered and
    # only set via the select_chart_type or select_line chart methods.  
    # def determine_chart_type(self, update_chart: bool = True):
    #     &#34;&#34;&#34; Determine the chart type from the Trading Economics chart currently displayed in webdriver.
    #     This is done by checking the class of the selected chart type button in the chart. The chart type is determined by the class of the SVG element
    #     in the chart. This method will return the chart type as a string. 

    #     **Parameters:**
    #     - update_chart (bool): Whether to update the chart before determining the chart type. Default is False.
    #     &#34;&#34;&#34;
    #     if update_chart:
    #         self.update_chart()
    #     if not hasattr(self, &#34;chart_types&#34;) or not hasattr(self, &#34;expected_types&#34;):
    #         self.create_chart_types_dict()

    #     print(&#34;Chart types: &#34;, self.chart_types)
    #     print(&#34;determine_chart_type method: Expected chart types: &#34;, self.expected_types)
    #     res = self.chart_soup.select(&#34;.dkLabels-label-btn.selectedChartType&#34;)
        
    #     self.chart_type_svgs = {
    #         &#39;Column&#39;: &#39;M4,9.2h2.057143v9.8L4,19v-9.8ZM9.04,5h1.92v14h-1.92v-14Zm5.04,8h1.92v6h-1.92v-6Z&#39;,
    #         &#39;Spline&#39;: &#39;M1 15v-15h-1v16h16v-1h-15z&#39;,
    #         &#39;Areaspline&#39;: &#39;M1 15v-15h-1v16h16v-1h-15z&#39;,
    #         &#39;Stepline&#39;: &lt;rect height=&#34;0.8&#34; rx=&#34;0&#34; ry=&#34;0&#34; stroke-width=&#34;0&#34; transform=&#34;translate(2.2081 12.419091)&#34; width=&#34;10.1919&#34;&gt;&lt;/rect&gt;,
    #         &#39;Line&#39;: &#39;M3.5 18.49L9.5 12.48L13.5 16.48L22 6.92L20.59 5.51L13.5 13.48L9.5 9.48L2 16.99L3.5 18.49Z&#39;,
    #         &#39;Area&#39;: &#39;M1 15v-15h-1v16h16v-1h-15z&#39;}
    #     return res
    #     # print(&#34;Selected chart type buttons: &#34;, &#34;\n&#34;, res,&#34;\n&#34;)
    #     # for r in res:  # This is a list of the selected chart type buttons.
    #     #     print(&#34;Parent class: &#34;, r.parent, &#34;\n&#34;, r, &#34;\n&#34;, &#34;Child class: &#34;, r.children)
    #     #     if any(expected_type in r.parent[&#34;class&#34;] for expected_type in self.expected_types.values()):
    #     #         self.chart_type = r.parent[&#34;class&#34;][0]
    #     #         logger.info(f&#34;Chart type determined: {self.chart_type}&#34;)
    #     #         return self.chart_type
    #     logger.debug(&#34;Error determining chart tyoe: Chart type not found.&#34;)
    #     return None
    
    def get_element(self, selector: str = &#34;.highcharts-series path&#34;, selector_type=By.CSS_SELECTOR):
        &#34;&#34;&#34;Find element by selector. The data trace displayed on a Trading Economics chart is a PATH element in the SVG chart.
        This is selected using the CSS selector &#34;.highcharts-series path&#34; by default. The element is stored in the &#39;current_element&#39; attribute.
        It can be used to select other elements on the chart as well and assign that to current element attribute.
        
        **Parameters:**
        - selector (str): The CSS selector for the element to find.
        - selector_type (By): The type of selector to use, By.CSS_SELECTOR by default.

        **Returns:**
        - element: The found element or None if not found.
        &#34;&#34;&#34;
        try:
            element = self.wait.until(
                EC.presence_of_element_located((selector_type, selector))
            )
            self.current_element = element
            logger.info(f&#34;Element found and assigned to current_element attribute: {selector}&#34;)
            return element
        except TimeoutException:
            print(f&#34;Element not found: {selector}&#34;)
            logger.debug(f&#34;Element not found: {selector}&#34;)
            return None
        except Exception as e:
            print(f&#34;Error finding element: {str(e)}&#34;)
            logger.debug(f&#34;Error finding element: {str(e)}&#34;)
            return None
        
    def series_from_chart_soup(self, selector: str = &#34;.highcharts-tracker-line&#34;, 
                               invert_the_series: bool = True, 
                               set_max_datespan: bool = False,
                               local_run: bool = False,
                               use_chart_type: Literal[&#34;Line&#34;, &#34;Spline&#34;] = &#34;Spline&#34;):  
          
        &#34;&#34;&#34;Extract series data from element text. This extracts the plotted series from the svg chart by taking the PATH 
        element of the data tarace on the chart. Series values are pixel co-ordinates on the chart.

        **Parameters:**
        - invert_the_series (bool): Whether to invert the series values.
        - return_series (bool): whether or not to return the series at end. Series is assigned to self.series always.
        - set_max_datespan (bool): Whether to set the date span to MAX before extracting the series data. Default is False.
        - local_run (bool): Whether the method is being run to get the full date_span series or just extacting part of the series
        to then aggregate together the full series. Default is False.
        - use_chart_type (str): The chart type to use for the extraction of the series data. Default is &#34;Spline&#34;. This is used to set the chart type before extracting the series data.
        CUATION: This method may fail with certain types of charts. It is best to use Spline unless you have a reason to use another type.

        **Returns:**

        - series (pd.Series): The extracted series data that is the raw pixel co-ordinate values of the data trace on the svg chart.
        &#34;&#34;&#34;

        self.update_chart() # Update chart..

        self.select_chart_type(use_chart_type) ## Use a certain chart type for the extraction of the series data. May fail with certain types of charts.

        if set_max_datespan and self.date_span != &#34;MAX&#34;:
            self.set_date_span(&#34;MAX&#34;)
        logger.info(f&#34;Series path extraction method: Extracting series data from chart soup.&#34;) 
        logger.info(f&#34;Date span: {self.date_span}. Chart type: {self.chart_type}, URL: {self.last_url}.&#34;)
    
        datastrlist = self.chart_soup.select(selector)
        
        if len(datastrlist) &gt; 1:
            print(&#34;Multiple series found in the chart. Got to figure out which one to use... work to do here... This will not work yet, please report error.&#34;)
            raise ValueError(&#34;Multiple series found in the chart. Got to figure out which one to use... work to do here...&#34;)
        else:
            raw_series = self.chart_soup.select_one(&#34;.highcharts-graph&#34;)[&#34;d&#34;].split(&#34; &#34;)
    
        ser = pd.Series(raw_series)
        ser_num = pd.to_numeric(ser, errors=&#39;coerce&#39;).dropna()

        exvals = ser_num[::2]; yvals = ser_num[1::2]
        exvals = exvals.sort_values().to_list()
        yvals = yvals.to_list()
        series = pd.Series(yvals, index = exvals, name = &#34;Extracted Series&#34;)

        if local_run:
            y_axis = self.get_y_axis()
        else:
            y_axis = self.y_axis

        if invert_the_series:
            series = utils.invert_series(series, max_val = y_axis.index.max())
        
        if not local_run:
            self.trace_path_series_raw = series.copy()
         # Keep the raw pixel co-ordinate valued series extracted from the svg path element.
        logger.debug(f&#34;Raw data series extracted successfully: {series.head(2)}&#34;)
        self.series_extracted_from = use_chart_type  #Add this attribute so that the apply_x_index method knows which chart_type the series came from.
        self.series = series
        return series
    
    def custom_date_span(self, start_date: str = &#34;1900-01-01&#34;, end_date: str = datetime.date.today().strftime(&#34;%Y-%m-%d&#34;)) -&gt; bool:
        &#34;&#34;&#34;Set the date range on the active chart in the webdriver window. 
        This is done by entering the start and end dates into the date range input boxes
        
        Args:
            start_date (str): Start date in format YYYY-MM-DD
            end_date (str): End date in format YYYY-MM-DD
        &#34;&#34;&#34;

        if self.click_button(&#34;#dateInputsToggle&#34;):
            time.sleep(1)
            try:
                # Find elements
                start_input = self.wait.until(EC.presence_of_element_located((By.ID, &#34;d1&#34;)))
                end_input = self.wait.until(EC.presence_of_element_located((By.ID, &#34;d2&#34;)))
                
                # Clear existing text
                start_input.clear()
                end_input.clear()
                
                # Enter new dates
                start_input.send_keys(start_date)
                end_input.send_keys(end_date)
                
                # Press Enter to confirm
                end_input.send_keys(Keys.RETURN)
                self.date_span = {&#34;Custom&#34;: {&#34;start_date&#34;: start_date, &#34;end_date&#34;: end_date}}
                return True
                
            except Exception as e:
                logger.info(f&#34;Failed to enter dates: {e}&#34;)
                return False
        else:
            logger.info(&#34;Failed to open date range inputs&#34;)
            return False
    
    def get_datamax_min(self):
        &#34;&#34;&#34;Get the max and min data values for the series using y-axis values... This is deprecated and not used in the current version of the code.&#34;&#34;&#34;
        
        logger.debug(f&#34;get_datamax_min method, axisY0 = {self.y_axis.iloc[0]}, axisY1 = {self.y_axis.iloc[-1]}&#34;)
        px_range = self.y_axis.index[-1] - self.y_axis.index[0]
        labrange = self.y_axis.iloc[-1] - self.y_axis.iloc[0]
        self.unit_per_pix_alt2 = labrange/px_range
        print(&#34;unit_per_pix: &#34;, self.unit_per_pix)
        logger.debug(f&#34;unit_per_pix: {self.unit_per_pix}, alt2: {self.unit_per_pix_alt2}&#34;)
        self.datamax = round(self.y_axis.iloc[-1] - (self.y_axis.index[-1] - self.series.max())*self.unit_per_pix, 3)
        self.datamin = round(self.y_axis.iloc[0] + (self.series.min()-self.y_axis.index[0])*self.unit_per_pix, 3)
        print(&#34;datamax: &#34;, self.datamax, &#34;datamin: &#34;, self.datamin)
        logger.debug(f&#34;datamax: {self.datamax}, datamin: {self.datamin}&#34;)
        return self.datamax, self.datamin
    
    def scale_series(self, right_way_up: bool = True):
        &#34;&#34;&#34;Scale the series using the first and last values from the series pulled from the tooltip box. Uses the y axis limits and the max and min of the y axis
        to determine the scaling factor to convert pixel co-ordinates to data values. The scaling factor is stored in the self.axlims_upp attribute.&#34;&#34;&#34;

        if not right_way_up:
            max_val = self.y_axis.index.max()  # This should be the top pixel of the chart.
            self.series = utils.invert_series(self.series, max_val = max_val)

        if hasattr(self, &#34;start_end&#34;):
            y0 = self.start_end[&#34;start_value&#34;]; y1 = self.start_end[&#34;end_value&#34;]
            pix0 = self.series.iloc[0]; pix1 = self.series.iloc[-1]
            
            self.unit_per_px_alt = abs(y1 - y0) / abs(pix1 - pix0)  # Calculated from the start and end datapoints.
            
            if not hasattr(self, &#34;axis_limits&#34;):
                self.axis_limits = self.extract_axis_limits()
            ## Turns out that this formulation below is the best way to calculate the scaling factor for the chart.
            self.axlims_upp = (self.y_axis.iloc[-1] - self.y_axis.iloc[0]) / (self.axis_limits[&#34;y_max&#34;] - self.axis_limits[&#34;y_min&#34;])

            # if the start and end points are at similar values this will be problematic though. 
            logger.debug(&#34;Scale series method: &#34;
                        f&#34;Start value, end value: {y0}, {y1}, pix0, pix1: {pix0}, {pix1}, &#34;
                         f&#34;data units per chart pixel from start &amp; end points: {self.unit_per_px_alt}, &#34;
                         f&#34;unit_per_pix calculated from the y axis ticks: {self.unit_per_pix}, &#34;
                         f&#34;inverse of that: {1/self.unit_per_pix}, &#34;
                         f&#34;unit_per_pix from axis limits and self.y_axis (probably best way): {self.axlims_upp}&#34;)

            self.unscaled_series = self.series.copy()
            ##Does the Y axis cross zero? Where is the zero point??
            x_intercept = utils.find_zero_crossing(self.series)

            if x_intercept:
                logger.debug(f&#34;Y axis Series does cross zero at:  {x_intercept}&#34;)
                pix0 = x_intercept

            for i in range(len(self.series)):
                self.series.iloc[i] = (self.series.iloc[i] - pix0)*self.axlims_upp + y0
    
            self.series = self.series
        else:
            print(&#34;start_end not found, run get_datamax_min() first.&#34;)
            logger.debug(&#34;start_end not found, run get_datamax_min() first.&#34;)
            return

        return self.series
    
    def get_xlims_from_tooltips(self):
        &#34;&#34;&#34; Use the TooltipScraper class to get the start and end dates and some other points of the time series using the tooltip box displayed on the chart.
        Takes the latest num_points points from the chart and uses them to determine the frequency of the time series. The latest data is used
        in case the earlier data is of lower frequency which can sometimes occurr.
        
        **Parameters:**
        
        - force_rerun (bool): Whether to force a rerun of the method to get the start and end dates and frequency of the time series again. The method
        will not run again by default if done a second time and start_end and frequency attributes are already set. If the first run resulted in erroneous
        assignation of these attributes, set this to True to rerun the method. However, something may need to be changed if it is not working...&#34;&#34;&#34;
        if self.date_span != &#34;MAX&#34;:
            self.set_date_span(&#34;MAX&#34;)  ##Set date_span to MAX for start and end date pull...
        if self.chart_type != &#34;lineChart&#34;:
            self.select_chart_type(&#34;Line&#34;)

        if not hasattr(self, &#34;tooltip_scraper&#34;):
            self.tooltip_scraper = utils.TooltipScraper(parent_instance = self) # Create a tooltip scraper child object
        
        self.start_end = self.tooltip_scraper.first_last_dates()
        #print(&#34;Start and end dates scraped from tooltips: &#34;, self.start_end)

    def make_x_index(self, 
                     force_rerun_xlims: bool = False,
                     force_rerun_freqdet: bool = False):
        &#34;&#34;&#34;Make the DateTime Index for the series using the start and end dates scraped from the tooltips. 
        This uses Selenium and also scrapes the some of the latest datapoints from the tooltips on the chart in order to determine
        the frequency of the time series. It will take a bit of time to run.

        **Parameters:**
        - force_rerun_xlims (bool): Whether to force a rerun of the method to get the start and end dates and frequency of the time series again. The method
        will not run again by default if done a second time and start_end and frequency attributes are already set. 
        - force_rerun_freqdet (bool): Whether to force a rerun of the method to get the frequency of the time series again. The method
        will not run again by default if done a second time and frequency attribute is already set. 
        &#34;&#34;&#34;
        ## Update chart...
        self.update_chart()

        if not hasattr(self, &#34;tooltip_scraper&#34;):  # If the tooltip scraper object is not already created, create it.
            self.tooltip_scraper = utils.TooltipScraper(parent_instance = self) # Create a tooltip scraper child object

        print(&#34;Using selenium and tooltip scraping to construct the date time index for the time-series, this&#39;ll take a bit...&#34;)
        if force_rerun_xlims or not hasattr(self, &#34;start_end&#34;):
            self.get_xlims_from_tooltips()
        # Get the first and last datapoints from the chart at MAX datespan

        if self.start_end is not None:
            logger.info(f&#34;Start and end values scraped from tooltips: \n{self.start_end}&#34;)
        else:
            print(&#34;Error: Start and end values not found...pulling out....&#34;)
            logger.debug(f&#34;Error: Start and end values not found...pulling out....&#34;)
            return None
        
        ## Get the latest 10 or so points from the chart, date and value from tooltips, in order to determine the frequency of the time series.
        if force_rerun_freqdet or not hasattr(self, &#34;latest_points&#34;):
            datapoints = self.tooltip_scraper.get_latest_points(num_points = 5)  # Get the latest 10 points from the chart.
            self.latest_points = datapoints
            latest_dates = [datapoint[&#34;date&#34;] for datapoint in datapoints]
            print(&#34;Latest dates: &#34;, latest_dates)

            ## Get the frequency of the time series
            self.date_series = pd.Series(latest_dates[::-1]).astype(&#34;datetime64[ns]&#34;)
            self.frequency = utils.get_date_frequency(self.date_series)
        print(&#34;Frequency of time-series: &#34;, self.frequency)

        start_date = self.start_end[&#34;start_date&#34;]; end_date = self.start_end[&#34;end_date&#34;]
        dtIndex = self.dtIndex(start_date=start_date, end_date=end_date, ser_name=self.series_name)
        if dtIndex is not None:
            logger.info(f&#34;DateTimeIndex created successfully for the time-series.&#34;)
            self.x_index = dtIndex
            return dtIndex  
        else:
            logger.info(f&#34;Error creating DateTimeIndex for the time-series.&#34;)
            return None

    def get_y_axis(self, update_chart: bool = False, set_global_y_axis: bool = False):
        &#34;&#34;&#34;Get y-axis values from chart to make a y-axis series with tick labels and positions (pixel positions).
        Also gets the limits of both axis in pixel co-ordinates. A series containing the y-axis values and their pixel positions (as index) is assigned
        to the &#34;y_axis&#34; attribute. The &#34;axis_limits&#34; attribute is made too &amp; is  dictionary containing the pixel co-ordinates of the max and min for both x and y axis.

        **Parameters:**
        - update_chart (bool): Whether to update the chart before scraping the y-axis values. Default is False.
        - set_global_y_axis (bool): Whether to set the y-axis series as a global attribute of the class. Default is False.
        &#34;&#34;&#34;

        ##Get positions of y-axis gridlines
        y_heights = []
        if update_chart:
            self.update_chart()
        if set_global_y_axis and self.date_span != &#34;MAX&#34;:
            self.set_date_span(&#34;MAX&#34;)

        ## First get the pixel values of the max and min for both x and y axis.
        self.axis_limits = self.extract_axis_limits()

        ygrid = self.chart_soup.select(&#39;g.highcharts-grid.highcharts-yaxis-grid&#39;)
        gridlines = ygrid[1].findAll(&#39;path&#39;)
        for line in gridlines:
            y_heights.append(float(line.get(&#39;d&#39;).split(&#39; &#39;)[-1]))
        y_heights = sorted(y_heights)

        ##Get y-axis labels
        yax = self.chart_soup.select(&#39;g.highcharts-axis-labels.highcharts-yaxis-labels&#39;)
        textels = yax[1].find_all(&#39;text&#39;)

        # Replace metrc prefixes:
        yaxlabs = [utils.convert_metric_prefix(text.get_text()) if text.get_text().replace(&#39;,&#39;,&#39;&#39;).replace(&#39;.&#39;,&#39;&#39;).replace(&#39;-&#39;,&#39;&#39;).replace(&#39; &#39;,&#39;&#39;).isalnum() else text.get_text() for text in textels]
        logger.debug(f&#34;y-axis labels: {yaxlabs}&#34;)

        # convert to float...
        if any(isinstance(i, str) for i in yaxlabs):
            yaxlabs = [float(&#39;&#39;.join(filter(str.isdigit, i.replace(&#34;,&#34;, &#34;&#34;)))) if isinstance(i, str) else i for i in yaxlabs]
        pixheights = [float(height) for height in y_heights]
        pixheights.sort()

        ##Get px per unit for y-axis
        pxPerUnit = [abs((yaxlabs[i+1]- yaxlabs[i])/(pixheights[i+1]- pixheights[i])) for i in range(len(pixheights)-1)]
        average = sum(pxPerUnit)/len(pxPerUnit)
        if set_global_y_axis:
            self.unit_per_pix = average
        logger.debug(f&#34;Average px per unit for y-axis: {average}&#34;)  #Calculate the scaling for the chart so we can convert pixel co-ordinates to data values.

        yaxis = pd.Series(yaxlabs, index = pixheights, name = &#34;ytick_label&#34;)
        yaxis.index.rename(&#34;pixheight&#34;, inplace = True)
        try:
            yaxis = yaxis.astype(float)
        except:
            pass

        if yaxis is not None:
            logger.debug(f&#34;Y-axis values scraped successfully.&#34;)
            logger.info(f&#34;Y-axis values scraped successfully.&#34;)
        
        if set_global_y_axis:
            self.y_axis = yaxis

        return yaxis
    
    def dtIndex(self, start_date: str, end_date: str, ser_name: str = &#34;Time-series&#34;) -&gt; pd.DatetimeIndex:
        &#34;&#34;&#34;

        Create a date index for your series in self.series. Will first make an index to cover the full length of your series 
        and then resample to month start freq to match the format on Trading Economics.
        
        **Parameters:**
        - start_date (str) YYYY-MM-DD: The start date of your series
        - end_date (str) YYYY-MM-DD: The end date of your series
        - ser_name (str): The name TO GIVE the series
        &#34;&#34;&#34;

        if hasattr(self, &#34;series&#34;) and not hasattr(self, &#34;frequency&#34;):
            logger.info(&#34;Series found but frequency not known. Creating a datetime x-index for series with frequency determined by length of series.\
                        Returning dtIndex only.&#34;)
            dtIndex = pd.date_range(start = start_date, end=end_date, periods=len(self.series), inclusive=&#34;both&#34;)
            return dtIndex
        elif hasattr(self, &#34;series&#34;) and hasattr(self, &#34;frequency&#34;):
            dtIndex = pd.date_range(start = start_date, end=end_date, freq = self.frequency)
            new_ser = pd.Series(self.series.to_list(), index = dtIndex, name = ser_name)
            self.trace_path_series = new_ser.copy()
            new_ser = new_ser.resample(self.frequency).first()
            self.series = new_ser
            logger.info(f&#34;Series is already scraped, frequency and start, end dates are known. DatetimeIndex created\
                        for series, set as index and series resampled at the frequency: {self.frequency}. series attribute updated.&#34;)
            return dtIndex
        elif not hasattr(self, &#34;series&#34;) and hasattr(self, &#34;frequency&#34;):
            logger.debug(&#34;No series found, using frequency and start and end dates to create a datetime x-index.&#34;)
            dtIndex = pd.date_range(start = start_date, end=end_date, freq = self.frequency)
            return dtIndex
        else:
            logger.info(&#34;No series found, frequenc unknown get the series or frequency first. Returning None&#34;)
            return None 
        
    def apply_x_index(self, x_index: pd.DatetimeIndex = None, use_rounded_tempIndex: bool = False, redo_series: bool = False):
        &#34;&#34;&#34;Apply a datetime index to the series. This will set the datetime index as the index of the series and resample the series to the frequency
        of the datetime index. The series attribute of the class will be updated with the new series.

        **Parameters:**
        - x_index (pd.DatetimeIndex): The datetime index to apply to the series. If None, the x_index attribute of the class will be used.
        &#34;&#34;&#34;
        if x_index is None and not hasattr(self, &#34;x_index&#34;):
            print(&#34;No datetime x-index found. Run make_x_index() first.&#34;)
            return None
        elif x_index is None:
            x_index = self.x_index
        else:
            pass

        if redo_series:
            self.series = self.trace_path_series_raw.copy()

        if hasattr(self, &#34;series&#34;):
            if self.series_extracted_from == &#34;Line&#34;:
                if len(x_index) == len(self.series):
                    new_ser = pd.Series(self.series.to_list(), index = self.x_index, name = self.series_name)
                elif len(x_index) &gt; len(self.series):
                    print(&#34;Length of x_index is greater than length of series. This is unfortunate, dunno what to do here...&#34;)
                    return None
                else: # use_rounded_tempIndex:
                    temp_index = pd.date_range(start = x_index[0], end = x_index[-1], periods=len(self.series))
                    temp_index = utils.round_to_freq(temp_index, self.frequency)
                    new_ser = pd.Series(self.series.to_list(), index = temp_index, name = self.series_name)
                    new_ser = new_ser.resample(self.frequency).first()
            elif self.series_extracted_from == &#34;Spline&#34;:
                temp_index = pd.date_range(start = x_index[0], end = x_index[-1], periods=len(self.series))
                #print(&#34;temp_index: &#34;, temp_index, &#34;len series: &#34;, len(self.series), &#34;len x_index: &#34;, len(x_index))
                new_ser = pd.Series(self.series.to_list(), index = temp_index, name = self.series_name)
                self.trace_path_series = new_ser.copy()
                new_ser = new_ser.resample(self.frequency).first()
            else:
                logger.info(&#34;Series not extracted from Line or Spline chart. Cannot apply datetime index, go back and run the series_from_chart_soup method.&#34;)
                return None
            
            self.series = new_ser  # Update the series attribute with the new series.
            logger.info(f&#34;DateTimeIndex applied to series, series attribute updated.&#34;)
        else:
            logger.info(&#34;No series found, get the series first.&#34;)
            return None

    def extract_axis_limits(self):
        &#34;&#34;&#34;Extract axis limits from the chart in terms of pixel co-ordinates.&#34;&#34;&#34;
        logger.debug(f&#34;Extracting axis limits from the chart...&#34;)
        try:
            # Extract axis elements
            yax = self.chart_soup.select_one(&#34;g.highcharts-axis.highcharts-yaxis path.highcharts-axis-line&#34;)
            xax = self.chart_soup.select_one(&#34;g.highcharts-axis.highcharts-xaxis path.highcharts-axis-line&#34;)
            
            ylims = yax[&#34;d&#34;].replace(&#34;M&#34;, &#34;&#34;).replace(&#34;L&#34;, &#34;&#34;).strip().split(&#34; &#34;)
            ylims = [float(num) for num in ylims if len(num) &gt; 0][1::2]
            logger.debug(f&#34;yax: {ylims}&#34;)

            xlims = xax[&#34;d&#34;].replace(&#34;M&#34;, &#34;&#34;).replace(&#34;L&#34;, &#34;&#34;).strip().split(&#34; &#34;)
            xlims = [float(num) for num in xlims if len(num) &gt; 0][0::2]
            logger.debug(f&#34;xax: {xlims}&#34;)
            
            axis_limits = {
                &#39;x_min&#39;: xlims[0],
                &#39;x_max&#39;: xlims[1],
                &#39;y_min&#39;: ylims[0],
                &#39;y_max&#39;: ylims[1]
            }
            
            return axis_limits
        except Exception as e:
            print(f&#34;Error extracting axis limits: {str(e)}&#34;)
            logger.debug(f&#34;Error extracting axis limits: {str(e)}&#34;)
            return None
    
    def plot_series(self, series: pd.Series = None, 
                    annotation_text: str = None, 
                    dpi: int = 300, 
                    ann_box_pos: tuple = (0, - 0.2)):
        &#34;&#34;&#34;
        Plots the time series data using pandas with plotly as the backend. Plotly is set as the pandas backend in __init__.py for tedata.
        If you want to use matplotlib or other plotting library don&#39;t use this method, plot the series attribute data directly. If using jupyter
        you can set 

        **Parameters**
        - series (pd.Series): The series to plot. Default is None. If None, the series attribute of the class will be plotted.
        - annotation_text (str): Text to display in the annotation box at the bottom of the chart. Default is None. If None, the default annotation text
        will be created from the metadata.
        - dpi (int): The resolution of the plot in dots per inch. Default is 300.
        - ann_box_pos (tuple): The position of the annotation box on the chart. Default is (0, -0.23) which is bottom left.

        **Returns** None
        &#34;&#34;&#34;
        
        if series is None:
            series = self.series

        fig = series.plot()  # Plot the series using pandas, plotly needs to be set as the pandas plotting backend.

         # Existing title and label logic
        if hasattr(self, &#34;series_metadata&#34;):
            title = str(self.series_metadata[&#34;country&#34;]).capitalize() + &#34;: &#34; + str(self.series_metadata[&#34;title&#34;]).capitalize()
            ylabel = str(self.series_metadata[&#34;units&#34;]).capitalize()
            
            # Create default annotation text from metadata
            if annotation_text is None:
                annotation_text = (
                    f&#34;Source: {self.series_metadata[&#39;source&#39;]}&lt;br&gt;&#34;
                    f&#34;Original Source: {self.series_metadata[&#39;original_source&#39;]}&lt;br&gt;&#34;
                    f&#34;Frequency: {self.series_metadata[&#39;frequency&#39;]}&#34;
                )
        else:
            title = &#34;Time Series Plot&#34;
            ylabel = &#34;Value&#34;
            annotation_text = annotation_text or &#34;Source: Trading Economics&#34;

        # Add text annotation to bottom left
        fig.add_annotation(
            text=annotation_text,
            xref=&#34;paper&#34;, yref=&#34;paper&#34;,
            x=ann_box_pos[0], y=ann_box_pos[1],
            showarrow=False, font=dict(size=10),
            align=&#34;left&#34;,  xanchor=&#34;left&#34;,
            yanchor=&#34;bottom&#34;, bgcolor=&#34;rgba(255, 255, 255, 0.8)&#34;,
            bordercolor=&#34;black&#34;, borderwidth=1)

        # Label x and y axis
        fig.update_layout(
            legend=dict(
            title_text=&#34;&#34;,  # Remove legend title
            orientation=&#34;h&#34;,
            yanchor=&#34;bottom&#34;,
            y=-0.2,  # Adjust this value to move the legend further down
            xanchor=&#34;center&#34;,
            x=0.5
            ),
            yaxis_title=ylabel,
            xaxis_title=&#34;&#34;,
            title = title)

        # Show the figure
        fig.show()
        self.plot = fig

    def save_plot(self, filename: str = &#34;plot&#34;, save_path: str = os.getcwd(), dpi: int = 300, format: str = &#34;png&#34;):
        &#34;&#34;&#34;Save the plot to a file. The plot must be created using the plot_series method. This method will save the plot as a PNG image file.

        **Parameters**
        - filename (str): The name of the file to save the plot to. Default is &#39;plot.png&#39;.
        - save_path (str): The directory to save the plot to. Default is the current working directory.
        - dpi (int): The resolution of the plot in dots per inch. Default is 300.
        - format (str): The format to save the plot in. Default is &#39;png&#39;. Other options are: &#34;html&#34;, &#34;bmp&#34;, &#34;jpeg&#34;, &#34;jpg&#34;.
        Use &#34;html&#34; to save as an interactive plotly plot.

        :Returns: None
        &#34;&#34;&#34;

        if hasattr(self, &#34;plot&#34;):
            if format == &#34;html&#34;:
                self.plot.write_html(f&#34;{save_path}{fdel}{filename}.html&#34;)
                logger.info(f&#34;Plot saved as {save_path}{fdel}{filename}.html&#34;)
            else:
                self.plot.write_image(f&#34;{save_path}{fdel}{filename}.{format}&#34;, format=format, scale=dpi/100, width = 1400, height = 500)
                logger.info(f&#34;Plot saved as {filename}&#34;)
        else:
            print(&#34;Error: Plot not found. Run plot_series() method to create a plot.&#34;)
            logger.debug(&#34;Error: Plot not found. Run plot_series() method to create a plot.&#34;)

    def scrape_metadata(self):
        &#34;&#34;&#34;Scrape metadata from the page. This method scrapes metadata from the page and stores it in the &#39;metadata&#39; attribute. The metadata
        includes the title, indicator, country, length, frequency, source, , original source, id, start date, end date, min value, and max value of the series.
        It also scrapes a description of the series if available and stores it in the &#39;description&#39; attribute.
        &#34;&#34;&#34;

        self.metadata = {}
        logger.debug(f&#34;Scraping metadata for the series from the page...&#34;)

        try:
            self.metadata[&#34;units&#34;] = self.chart_soup.select_one(&#39;#singleIndChartUnit2&#39;).text
        except Exception as e:
            print(&#34;Units label not found: &#34;, {str(e)})
            self.metadata[&#34;units&#34;] = &#34;a.u&#34;
        
        try:
            self.metadata[&#34;original_source&#34;] = self.chart_soup.select_one(&#39;#singleIndChartUnit&#39;).text
        except Exception as e:
            print(&#34;original_source label not found: &#34;, {str(e)})
            self.metadata[&#34;original_source&#34;] = &#34;unknown&#34;

        if hasattr(self, &#34;series&#34;):
            if hasattr(self, &#34;page_soup&#34;):
                heads = self.page_soup.select(&#34;#ctl00_Head1&#34;)
                self.metadata[&#34;title&#34;] = heads[0].title.text.strip()
            else:
                self.metadata[&#34;title&#34;] = self.last_url.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;)  # Use URL if can&#39;t find the title
            self.metadata[&#34;indicator&#34;] = self.last_url.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;)  
            self.metadata[&#34;country&#34;] = self.last_url.split(&#34;/&#34;)[-2].replace(&#34;-&#34;, &#34; &#34;) 
            self.metadata[&#34;length&#34;] = len(self.series)
            self.metadata[&#34;frequency&#34;] = self.frequency  
            self.metadata[&#34;source&#34;] = &#34;Trading Economics&#34; 
            self.metadata[&#34;id&#34;] = &#34;/&#34;.join(self.last_url.split(&#34;/&#34;)[-2:])
            self.metadata[&#34;start_date&#34;] = self.series.index[0].strftime(&#34;%Y-%m-%d&#34;)
            self.metadata[&#34;end_date&#34;] = self.series.index[-1].strftime(&#34;%Y-%m-%d&#34;)
            self.metadata[&#34;min_value&#34;] = float(self.series.min())
            self.metadata[&#34;max_value&#34;] = float(self.series.max())
            logger.info(f&#34;\nSeries metadata: \n {self.metadata}&#34;)

        try:
            desc_card = self.page_soup.select_one(&#34;#item_definition&#34;)
            header_text = desc_card.select_one(&#39;.card-header&#39;).text.strip()
            if header_text.lower() == self.metadata[&#34;title&#34;].lower():
                self.metadata[&#34;description&#34;] = desc_card.select_one(&#39;.card-body&#39;).text.strip()
            else:
                print(&#34;Description card title does not match series title.&#34;)
                self.metadata[&#34;description&#34;] = &#34;Description not found.&#34;
        except Exception as e:
            print(&#34;Description card not found: &#34;, {str(e)})

        self.series_metadata = pd.Series(self.metadata)
        if self.metadata is not None:
            logger.debug(f&#34;Metadata scraped successfully: {self.metadata}&#34;)

    def get_page_source(self):
        &#34;&#34;&#34;Get current page source after interactions&#34;&#34;&#34;
        return self.driver.page_source
    
    def close(self):
        &#34;&#34;&#34;Clean up resources&#34;&#34;&#34;
        if self.driver:
            self.driver.quit()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()</code></pre>
</details>
<div class="desc"><p>Class for scraping data from Trading Economics website. This is the main workhorse of the module.
It is designed to scrape data from the Trading Economics website using Selenium and BeautifulSoup.
It can load a page, click buttons, extract data from elements, and plot the extracted data. Uses multiple inheritance
from the Generic_Webdriver and SharedWebDriverState classes. This enables creation of TooltipScraper child classes that have
synced atributes such as "chart_soup", "chart_type" &amp; "date_span" &amp; share the same webdriver object. This is useful for scraping.</p>
<p><strong>Init Parameters:</strong>
- **kwargs (dict): Keyword
arguments to pass to the Generic_Webdriver class. These are the same as the Generic_Webdriver class.
These are:
- driver (webdriver): A Selenium WebDriver object, can put in an active one or make a new one for a new URL.
- use_existing_driver (bool): Whether to use an existing driver in the namespace. If True, the driver parameter is ignored. Default is False.
- browser (str): The browser to use for scraping, either 'chrome' or 'firefox'.
- headless (bool): Whether to run the browser in headless mode (show no window).</p>
<p>Initialize shared state attributes, it is chart_type and date_span which we want to keep synced between the classes.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tedata.base.Generic_Webdriver" href="base.html#tedata.base.Generic_Webdriver">Generic_Webdriver</a></li>
<li><a title="tedata.base.SharedWebDriverState" href="base.html#tedata.base.SharedWebDriverState">SharedWebDriverState</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tedata.utils.TooltipScraper" href="utils.html#tedata.utils.TooltipScraper">TooltipScraper</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tedata.scraper.TE_Scraper.BrowserType"><code class="name">var <span class="ident">BrowserType</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tedata.scraper.TE_Scraper.apply_x_index"><code class="name flex">
<span>def <span class="ident">apply_x_index</span></span>(<span>self,<br>x_index: pandas.core.indexes.datetimes.DatetimeIndex = None,<br>use_rounded_tempIndex: bool = False,<br>redo_series: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_x_index(self, x_index: pd.DatetimeIndex = None, use_rounded_tempIndex: bool = False, redo_series: bool = False):
    &#34;&#34;&#34;Apply a datetime index to the series. This will set the datetime index as the index of the series and resample the series to the frequency
    of the datetime index. The series attribute of the class will be updated with the new series.

    **Parameters:**
    - x_index (pd.DatetimeIndex): The datetime index to apply to the series. If None, the x_index attribute of the class will be used.
    &#34;&#34;&#34;
    if x_index is None and not hasattr(self, &#34;x_index&#34;):
        print(&#34;No datetime x-index found. Run make_x_index() first.&#34;)
        return None
    elif x_index is None:
        x_index = self.x_index
    else:
        pass

    if redo_series:
        self.series = self.trace_path_series_raw.copy()

    if hasattr(self, &#34;series&#34;):
        if self.series_extracted_from == &#34;Line&#34;:
            if len(x_index) == len(self.series):
                new_ser = pd.Series(self.series.to_list(), index = self.x_index, name = self.series_name)
            elif len(x_index) &gt; len(self.series):
                print(&#34;Length of x_index is greater than length of series. This is unfortunate, dunno what to do here...&#34;)
                return None
            else: # use_rounded_tempIndex:
                temp_index = pd.date_range(start = x_index[0], end = x_index[-1], periods=len(self.series))
                temp_index = utils.round_to_freq(temp_index, self.frequency)
                new_ser = pd.Series(self.series.to_list(), index = temp_index, name = self.series_name)
                new_ser = new_ser.resample(self.frequency).first()
        elif self.series_extracted_from == &#34;Spline&#34;:
            temp_index = pd.date_range(start = x_index[0], end = x_index[-1], periods=len(self.series))
            #print(&#34;temp_index: &#34;, temp_index, &#34;len series: &#34;, len(self.series), &#34;len x_index: &#34;, len(x_index))
            new_ser = pd.Series(self.series.to_list(), index = temp_index, name = self.series_name)
            self.trace_path_series = new_ser.copy()
            new_ser = new_ser.resample(self.frequency).first()
        else:
            logger.info(&#34;Series not extracted from Line or Spline chart. Cannot apply datetime index, go back and run the series_from_chart_soup method.&#34;)
            return None
        
        self.series = new_ser  # Update the series attribute with the new series.
        logger.info(f&#34;DateTimeIndex applied to series, series attribute updated.&#34;)
    else:
        logger.info(&#34;No series found, get the series first.&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Apply a datetime index to the series. This will set the datetime index as the index of the series and resample the series to the frequency
of the datetime index. The series attribute of the class will be updated with the new series.</p>
<p><strong>Parameters:</strong>
- x_index (pd.DatetimeIndex): The datetime index to apply to the series. If None, the x_index attribute of the class will be used.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.click_button"><code class="name flex">
<span>def <span class="ident">click_button</span></span>(<span>self, selector, selector_type='css selector')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def click_button(self, selector, selector_type=By.CSS_SELECTOR):
    &#34;&#34;&#34;Click button using webdriver and wait for response.
    
    **Parameters:**
    - selector (str): The CSS selector for the button to click.
    - selector_type (By): The type of selector to use, By.CSS_SELECTOR by default.&#34;&#34;&#34;

    try:
        # Wait for element to be clickable
        button = self.wait.until(
            EC.element_to_be_clickable((selector_type, selector))
        )
        # Scroll element into view
        time.sleep(0.25)  # Brief pause after scroll
        button.click()
        time.sleep(0.75)
        return True
    except TimeoutException:
        logger.info(f&#34;Button not found or not clickable: {selector}&#34;)
        return False
    except Exception as e:
        logger.info(f&#34;Error clicking button: {str(e)}&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Click button using webdriver and wait for response.</p>
<p><strong>Parameters:</strong>
- selector (str): The CSS selector for the button to click.
- selector_type (By): The type of selector to use, By.CSS_SELECTOR by default.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.click_max_button"><code class="name flex">
<span>def <span class="ident">click_max_button</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def click_max_button(self):
    &#34;&#34;&#34;Click the button that selects the maximum date range on the chart. This is usually the &#39;MAX&#39; button and is used to select the maximum date range for the chart.
    The method will find the button and click it. It will also wait for the chart to update after clicking the button.&#34;&#34;&#34;
    max_selector = self.find_max_button()
    if self.click_button(max_selector):
        time.sleep(1)
        logger.info(&#34;MAX button clicked successfully.&#34;)
        self.date_span = &#34;MAX&#34;
        self.update_chart()
    else:
        logger.debug(&#34;Error clicking MAX button.&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Click the button that selects the maximum date range on the chart. This is usually the 'MAX' button and is used to select the maximum date range for the chart.
The method will find the button and click it. It will also wait for the chart to update after clicking the button.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;Clean up resources&#34;&#34;&#34;
    if self.driver:
        self.driver.quit()</code></pre>
</details>
<div class="desc"><p>Clean up resources</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.create_chart_types_dict"><code class="name flex">
<span>def <span class="ident">create_chart_types_dict</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_chart_types_dict(self):
    &#34;&#34;&#34;Create a dictionary of chart types and their CSS selectors. This is used to select the chart type on the Trading Economics chart.
    The dictionary is stored in the chart_types attribute of the class. The keys are the names of the chart types and the values are the CSS selectors
    for the chart type buttons on the chart.&#34;&#34;&#34;

    hart_types = self.chart_soup.select_one(&#34;#chart &gt; div &gt; div &gt; div.hawk-header &gt; div &gt; div.pickChartTypes &gt; div &gt; div&#34;)
    self.chart_types = {child[&#34;title&#34;]: &#34;.&#34;+child[&#34;class&#34;][0]+&#34; .&#34;+ child.button[&#34;class&#34;][0] for child in hart_types.children}
    self.expected_types = {chart_type: self.chart_types[chart_type].split(&#34; &#34;)[0].replace(&#34;.&#34;, &#39;&#39;) for chart_type in self.chart_types.keys()}
    logger.info(f&#34;Chart types dictionary created successfully: {self.chart_types.keys()}&#34;)</code></pre>
</details>
<div class="desc"><p>Create a dictionary of chart types and their CSS selectors. This is used to select the chart type on the Trading Economics chart.
The dictionary is stored in the chart_types attribute of the class. The keys are the names of the chart types and the values are the CSS selectors
for the chart type buttons on the chart.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.custom_date_span"><code class="name flex">
<span>def <span class="ident">custom_date_span</span></span>(<span>self, start_date: str = '1900-01-01', end_date: str = '2025-02-14') ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def custom_date_span(self, start_date: str = &#34;1900-01-01&#34;, end_date: str = datetime.date.today().strftime(&#34;%Y-%m-%d&#34;)) -&gt; bool:
    &#34;&#34;&#34;Set the date range on the active chart in the webdriver window. 
    This is done by entering the start and end dates into the date range input boxes
    
    Args:
        start_date (str): Start date in format YYYY-MM-DD
        end_date (str): End date in format YYYY-MM-DD
    &#34;&#34;&#34;

    if self.click_button(&#34;#dateInputsToggle&#34;):
        time.sleep(1)
        try:
            # Find elements
            start_input = self.wait.until(EC.presence_of_element_located((By.ID, &#34;d1&#34;)))
            end_input = self.wait.until(EC.presence_of_element_located((By.ID, &#34;d2&#34;)))
            
            # Clear existing text
            start_input.clear()
            end_input.clear()
            
            # Enter new dates
            start_input.send_keys(start_date)
            end_input.send_keys(end_date)
            
            # Press Enter to confirm
            end_input.send_keys(Keys.RETURN)
            self.date_span = {&#34;Custom&#34;: {&#34;start_date&#34;: start_date, &#34;end_date&#34;: end_date}}
            return True
            
        except Exception as e:
            logger.info(f&#34;Failed to enter dates: {e}&#34;)
            return False
    else:
        logger.info(&#34;Failed to open date range inputs&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Set the date range on the active chart in the webdriver window.
This is done by entering the start and end dates into the date range input boxes</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start_date</code></strong> :&ensp;<code>str</code></dt>
<dd>Start date in format YYYY-MM-DD</dd>
<dt><strong><code>end_date</code></strong> :&ensp;<code>str</code></dt>
<dd>End date in format YYYY-MM-DD</dd>
</dl></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.determine_date_span"><code class="name flex">
<span>def <span class="ident">determine_date_span</span></span>(<span>self, update_chart: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def determine_date_span(self, update_chart: bool = True):
    &#34;&#34;&#34;Determine the selected date span from the Trading Economics chart currently displayed in webdriver.&#34;&#34;&#34;

    if update_chart: 
        self.update_chart()
    ## Populate the date spans dictionary
    buts = self.chart_soup.select(&#34;#dateSpansDiv&#34;)
    datebut = buts[0] if isinstance(buts, list) else buts
    self.date_spans = OrderedDict()
    for i, child in enumerate(datebut.children):
        selector = f&#34;a.{child[&#39;class&#39;][0] if isinstance(child[&#39;class&#39;], list) else child[&#39;class&#39;]}:nth-child({i+1})&#34;
        self.date_spans[child.text] = selector

    ## Find the selected date span
    if len(buts) == 1:
        result = buts[0].children
    elif len(buts) &gt; 1:
        print(&#34;Multiple date spans found&#34;)
        return buts
    else:
        print(&#34;No date spans found&#34;)
        return None

    for r in result:
        #print(&#34;Date span element: &#34;, r)
        if &#34;selected&#34;in r[&#34;class&#34;]:
            date_span = {r.text: r}
            return date_span
        else:
            return None</code></pre>
</details>
<div class="desc"><p>Determine the selected date span from the Trading Economics chart currently displayed in webdriver.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.dtIndex"><code class="name flex">
<span>def <span class="ident">dtIndex</span></span>(<span>self, start_date: str, end_date: str, ser_name: str = 'Time-series') ‑> pandas.core.indexes.datetimes.DatetimeIndex</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dtIndex(self, start_date: str, end_date: str, ser_name: str = &#34;Time-series&#34;) -&gt; pd.DatetimeIndex:
    &#34;&#34;&#34;

    Create a date index for your series in self.series. Will first make an index to cover the full length of your series 
    and then resample to month start freq to match the format on Trading Economics.
    
    **Parameters:**
    - start_date (str) YYYY-MM-DD: The start date of your series
    - end_date (str) YYYY-MM-DD: The end date of your series
    - ser_name (str): The name TO GIVE the series
    &#34;&#34;&#34;

    if hasattr(self, &#34;series&#34;) and not hasattr(self, &#34;frequency&#34;):
        logger.info(&#34;Series found but frequency not known. Creating a datetime x-index for series with frequency determined by length of series.\
                    Returning dtIndex only.&#34;)
        dtIndex = pd.date_range(start = start_date, end=end_date, periods=len(self.series), inclusive=&#34;both&#34;)
        return dtIndex
    elif hasattr(self, &#34;series&#34;) and hasattr(self, &#34;frequency&#34;):
        dtIndex = pd.date_range(start = start_date, end=end_date, freq = self.frequency)
        new_ser = pd.Series(self.series.to_list(), index = dtIndex, name = ser_name)
        self.trace_path_series = new_ser.copy()
        new_ser = new_ser.resample(self.frequency).first()
        self.series = new_ser
        logger.info(f&#34;Series is already scraped, frequency and start, end dates are known. DatetimeIndex created\
                    for series, set as index and series resampled at the frequency: {self.frequency}. series attribute updated.&#34;)
        return dtIndex
    elif not hasattr(self, &#34;series&#34;) and hasattr(self, &#34;frequency&#34;):
        logger.debug(&#34;No series found, using frequency and start and end dates to create a datetime x-index.&#34;)
        dtIndex = pd.date_range(start = start_date, end=end_date, freq = self.frequency)
        return dtIndex
    else:
        logger.info(&#34;No series found, frequenc unknown get the series or frequency first. Returning None&#34;)
        return None </code></pre>
</details>
<div class="desc"><p>Create a date index for your series in self.series. Will first make an index to cover the full length of your series
and then resample to month start freq to match the format on Trading Economics.</p>
<p><strong>Parameters:</strong>
- start_date (str) YYYY-MM-DD: The start date of your series
- end_date (str) YYYY-MM-DD: The end date of your series
- ser_name (str): The name TO GIVE the series</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.extract_axis_limits"><code class="name flex">
<span>def <span class="ident">extract_axis_limits</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_axis_limits(self):
    &#34;&#34;&#34;Extract axis limits from the chart in terms of pixel co-ordinates.&#34;&#34;&#34;
    logger.debug(f&#34;Extracting axis limits from the chart...&#34;)
    try:
        # Extract axis elements
        yax = self.chart_soup.select_one(&#34;g.highcharts-axis.highcharts-yaxis path.highcharts-axis-line&#34;)
        xax = self.chart_soup.select_one(&#34;g.highcharts-axis.highcharts-xaxis path.highcharts-axis-line&#34;)
        
        ylims = yax[&#34;d&#34;].replace(&#34;M&#34;, &#34;&#34;).replace(&#34;L&#34;, &#34;&#34;).strip().split(&#34; &#34;)
        ylims = [float(num) for num in ylims if len(num) &gt; 0][1::2]
        logger.debug(f&#34;yax: {ylims}&#34;)

        xlims = xax[&#34;d&#34;].replace(&#34;M&#34;, &#34;&#34;).replace(&#34;L&#34;, &#34;&#34;).strip().split(&#34; &#34;)
        xlims = [float(num) for num in xlims if len(num) &gt; 0][0::2]
        logger.debug(f&#34;xax: {xlims}&#34;)
        
        axis_limits = {
            &#39;x_min&#39;: xlims[0],
            &#39;x_max&#39;: xlims[1],
            &#39;y_min&#39;: ylims[0],
            &#39;y_max&#39;: ylims[1]
        }
        
        return axis_limits
    except Exception as e:
        print(f&#34;Error extracting axis limits: {str(e)}&#34;)
        logger.debug(f&#34;Error extracting axis limits: {str(e)}&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Extract axis limits from the chart in terms of pixel co-ordinates.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.find_max_button"><code class="name flex">
<span>def <span class="ident">find_max_button</span></span>(<span>self, selector: str = '#dateSpansDiv')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_max_button(self, selector: str = &#34;#dateSpansDiv&#34;):
    &#34;&#34;&#34;Find the button on the chart that selects the maximum date range and return the CSS selector for it.
    The button is usually labelled &#39;MAX&#39; and is used to select the maximum date range for the chart. The selector for the button is
    usually &#39;#dateSpansDiv&#39; but can be changed if the button is not found. The method will return the CSS selector for the button.
    This will also create an atrribute &#39;date_spans&#39; which is a dictionary containing the text of the date span buttons and their CSS selectors.&#34;&#34;&#34;

    try:
        buts = self.page_soup.select_one(selector)
        datebut = buts[0] if isinstance(buts, list) else buts
        self.date_spans = {child.text: f&#34;a.{child[&#39;class&#39;][0] if isinstance(child[&#39;class&#39;], list) else child[&#39;class&#39;]}:nth-child({i+1})&#34; for i, child in enumerate(datebut.children)}

        if &#34;MAX&#34; in self.date_spans.keys():
            max_selector = self.date_spans[&#34;MAX&#34;]
        else:
            raise ValueError(&#34;MAX button not found.&#34;)
        logger.debug(f&#34;MAX button found for chart at URL: {self.last_url}, selector: {max_selector}&#34;)
        
        return max_selector
    except Exception as e:
        print(f&#34;Error finding date spans buttons: {str(e)}&#34;)
        logger.debug(f&#34;Error finding date spans buttons: {str(e)}&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Find the button on the chart that selects the maximum date range and return the CSS selector for it.
The button is usually labelled 'MAX' and is used to select the maximum date range for the chart. The selector for the button is
usually '#dateSpansDiv' but can be changed if the button is not found. The method will return the CSS selector for the button.
This will also create an atrribute 'date_spans' which is a dictionary containing the text of the date span buttons and their CSS selectors.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.get_datamax_min"><code class="name flex">
<span>def <span class="ident">get_datamax_min</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_datamax_min(self):
    &#34;&#34;&#34;Get the max and min data values for the series using y-axis values... This is deprecated and not used in the current version of the code.&#34;&#34;&#34;
    
    logger.debug(f&#34;get_datamax_min method, axisY0 = {self.y_axis.iloc[0]}, axisY1 = {self.y_axis.iloc[-1]}&#34;)
    px_range = self.y_axis.index[-1] - self.y_axis.index[0]
    labrange = self.y_axis.iloc[-1] - self.y_axis.iloc[0]
    self.unit_per_pix_alt2 = labrange/px_range
    print(&#34;unit_per_pix: &#34;, self.unit_per_pix)
    logger.debug(f&#34;unit_per_pix: {self.unit_per_pix}, alt2: {self.unit_per_pix_alt2}&#34;)
    self.datamax = round(self.y_axis.iloc[-1] - (self.y_axis.index[-1] - self.series.max())*self.unit_per_pix, 3)
    self.datamin = round(self.y_axis.iloc[0] + (self.series.min()-self.y_axis.index[0])*self.unit_per_pix, 3)
    print(&#34;datamax: &#34;, self.datamax, &#34;datamin: &#34;, self.datamin)
    logger.debug(f&#34;datamax: {self.datamax}, datamin: {self.datamin}&#34;)
    return self.datamax, self.datamin</code></pre>
</details>
<div class="desc"><p>Get the max and min data values for the series using y-axis values&hellip; This is deprecated and not used in the current version of the code.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.get_element"><code class="name flex">
<span>def <span class="ident">get_element</span></span>(<span>self, selector: str = '.highcharts-series path', selector_type='css selector')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_element(self, selector: str = &#34;.highcharts-series path&#34;, selector_type=By.CSS_SELECTOR):
    &#34;&#34;&#34;Find element by selector. The data trace displayed on a Trading Economics chart is a PATH element in the SVG chart.
    This is selected using the CSS selector &#34;.highcharts-series path&#34; by default. The element is stored in the &#39;current_element&#39; attribute.
    It can be used to select other elements on the chart as well and assign that to current element attribute.
    
    **Parameters:**
    - selector (str): The CSS selector for the element to find.
    - selector_type (By): The type of selector to use, By.CSS_SELECTOR by default.

    **Returns:**
    - element: The found element or None if not found.
    &#34;&#34;&#34;
    try:
        element = self.wait.until(
            EC.presence_of_element_located((selector_type, selector))
        )
        self.current_element = element
        logger.info(f&#34;Element found and assigned to current_element attribute: {selector}&#34;)
        return element
    except TimeoutException:
        print(f&#34;Element not found: {selector}&#34;)
        logger.debug(f&#34;Element not found: {selector}&#34;)
        return None
    except Exception as e:
        print(f&#34;Error finding element: {str(e)}&#34;)
        logger.debug(f&#34;Error finding element: {str(e)}&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Find element by selector. The data trace displayed on a Trading Economics chart is a PATH element in the SVG chart.
This is selected using the CSS selector ".highcharts-series path" by default. The element is stored in the 'current_element' attribute.
It can be used to select other elements on the chart as well and assign that to current element attribute.</p>
<p><strong>Parameters:</strong>
- selector (str): The CSS selector for the element to find.
- selector_type (By): The type of selector to use, By.CSS_SELECTOR by default.</p>
<p><strong>Returns:</strong>
- element: The found element or None if not found.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.get_page_source"><code class="name flex">
<span>def <span class="ident">get_page_source</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_page_source(self):
    &#34;&#34;&#34;Get current page source after interactions&#34;&#34;&#34;
    return self.driver.page_source</code></pre>
</details>
<div class="desc"><p>Get current page source after interactions</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.get_xlims_from_tooltips"><code class="name flex">
<span>def <span class="ident">get_xlims_from_tooltips</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_xlims_from_tooltips(self):
    &#34;&#34;&#34; Use the TooltipScraper class to get the start and end dates and some other points of the time series using the tooltip box displayed on the chart.
    Takes the latest num_points points from the chart and uses them to determine the frequency of the time series. The latest data is used
    in case the earlier data is of lower frequency which can sometimes occurr.
    
    **Parameters:**
    
    - force_rerun (bool): Whether to force a rerun of the method to get the start and end dates and frequency of the time series again. The method
    will not run again by default if done a second time and start_end and frequency attributes are already set. If the first run resulted in erroneous
    assignation of these attributes, set this to True to rerun the method. However, something may need to be changed if it is not working...&#34;&#34;&#34;
    if self.date_span != &#34;MAX&#34;:
        self.set_date_span(&#34;MAX&#34;)  ##Set date_span to MAX for start and end date pull...
    if self.chart_type != &#34;lineChart&#34;:
        self.select_chart_type(&#34;Line&#34;)

    if not hasattr(self, &#34;tooltip_scraper&#34;):
        self.tooltip_scraper = utils.TooltipScraper(parent_instance = self) # Create a tooltip scraper child object
    
    self.start_end = self.tooltip_scraper.first_last_dates()
    #print(&#34;Start and end dates scraped from tooltips: &#34;, self.start_end)</code></pre>
</details>
<div class="desc"><p>Use the TooltipScraper class to get the start and end dates and some other points of the time series using the tooltip box displayed on the chart.
Takes the latest num_points points from the chart and uses them to determine the frequency of the time series. The latest data is used
in case the earlier data is of lower frequency which can sometimes occurr.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>force_rerun (bool): Whether to force a rerun of the method to get the start and end dates and frequency of the time series again. The method
will not run again by default if done a second time and start_end and frequency attributes are already set. If the first run resulted in erroneous
assignation of these attributes, set this to True to rerun the method. However, something may need to be changed if it is not working&hellip;</li>
</ul></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.get_y_axis"><code class="name flex">
<span>def <span class="ident">get_y_axis</span></span>(<span>self, update_chart: bool = False, set_global_y_axis: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_y_axis(self, update_chart: bool = False, set_global_y_axis: bool = False):
    &#34;&#34;&#34;Get y-axis values from chart to make a y-axis series with tick labels and positions (pixel positions).
    Also gets the limits of both axis in pixel co-ordinates. A series containing the y-axis values and their pixel positions (as index) is assigned
    to the &#34;y_axis&#34; attribute. The &#34;axis_limits&#34; attribute is made too &amp; is  dictionary containing the pixel co-ordinates of the max and min for both x and y axis.

    **Parameters:**
    - update_chart (bool): Whether to update the chart before scraping the y-axis values. Default is False.
    - set_global_y_axis (bool): Whether to set the y-axis series as a global attribute of the class. Default is False.
    &#34;&#34;&#34;

    ##Get positions of y-axis gridlines
    y_heights = []
    if update_chart:
        self.update_chart()
    if set_global_y_axis and self.date_span != &#34;MAX&#34;:
        self.set_date_span(&#34;MAX&#34;)

    ## First get the pixel values of the max and min for both x and y axis.
    self.axis_limits = self.extract_axis_limits()

    ygrid = self.chart_soup.select(&#39;g.highcharts-grid.highcharts-yaxis-grid&#39;)
    gridlines = ygrid[1].findAll(&#39;path&#39;)
    for line in gridlines:
        y_heights.append(float(line.get(&#39;d&#39;).split(&#39; &#39;)[-1]))
    y_heights = sorted(y_heights)

    ##Get y-axis labels
    yax = self.chart_soup.select(&#39;g.highcharts-axis-labels.highcharts-yaxis-labels&#39;)
    textels = yax[1].find_all(&#39;text&#39;)

    # Replace metrc prefixes:
    yaxlabs = [utils.convert_metric_prefix(text.get_text()) if text.get_text().replace(&#39;,&#39;,&#39;&#39;).replace(&#39;.&#39;,&#39;&#39;).replace(&#39;-&#39;,&#39;&#39;).replace(&#39; &#39;,&#39;&#39;).isalnum() else text.get_text() for text in textels]
    logger.debug(f&#34;y-axis labels: {yaxlabs}&#34;)

    # convert to float...
    if any(isinstance(i, str) for i in yaxlabs):
        yaxlabs = [float(&#39;&#39;.join(filter(str.isdigit, i.replace(&#34;,&#34;, &#34;&#34;)))) if isinstance(i, str) else i for i in yaxlabs]
    pixheights = [float(height) for height in y_heights]
    pixheights.sort()

    ##Get px per unit for y-axis
    pxPerUnit = [abs((yaxlabs[i+1]- yaxlabs[i])/(pixheights[i+1]- pixheights[i])) for i in range(len(pixheights)-1)]
    average = sum(pxPerUnit)/len(pxPerUnit)
    if set_global_y_axis:
        self.unit_per_pix = average
    logger.debug(f&#34;Average px per unit for y-axis: {average}&#34;)  #Calculate the scaling for the chart so we can convert pixel co-ordinates to data values.

    yaxis = pd.Series(yaxlabs, index = pixheights, name = &#34;ytick_label&#34;)
    yaxis.index.rename(&#34;pixheight&#34;, inplace = True)
    try:
        yaxis = yaxis.astype(float)
    except:
        pass

    if yaxis is not None:
        logger.debug(f&#34;Y-axis values scraped successfully.&#34;)
        logger.info(f&#34;Y-axis values scraped successfully.&#34;)
    
    if set_global_y_axis:
        self.y_axis = yaxis

    return yaxis</code></pre>
</details>
<div class="desc"><p>Get y-axis values from chart to make a y-axis series with tick labels and positions (pixel positions).
Also gets the limits of both axis in pixel co-ordinates. A series containing the y-axis values and their pixel positions (as index) is assigned
to the "y_axis" attribute. The "axis_limits" attribute is made too &amp; is
dictionary containing the pixel co-ordinates of the max and min for both x and y axis.</p>
<p><strong>Parameters:</strong>
- update_chart (bool): Whether to update the chart before scraping the y-axis values. Default is False.
- set_global_y_axis (bool): Whether to set the y-axis series as a global attribute of the class. Default is False.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.load_page"><code class="name flex">
<span>def <span class="ident">load_page</span></span>(<span>self, url, wait_time=2)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_page(self, url, wait_time=2):
    &#34;&#34;&#34;Load page and wait for it to be ready&#34;&#34;&#34;

    self.last_url = url
    self.series_name = url.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;)
    try:
        self.driver.get(url)
        #logger.debug(f&#34;Page loaded successfully: {url}&#34;)
        logger.info(f&#34;WebPage at {url} loaded successfully.&#34;)
        time.sleep(wait_time)  # Basic wait for page load
        self.full_page = self.get_page_source()
        self.page_soup = BeautifulSoup(self.full_page, &#39;html.parser&#39;)
        self.chart_soup = self.page_soup.select_one(&#34;#chart&#34;)  #Make a bs4 object from the #chart element of the page.
        self.full_chart = self.chart_soup.contents
        self.create_chart_types_dict() # Create the chart types dictionary for the chart.
        return True
    except Exception as e:
        print(f&#34;Error loading page: {str(e)}&#34;)
        logger.debug(f&#34;Error loading page: {str(e)}&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Load page and wait for it to be ready</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.make_x_index"><code class="name flex">
<span>def <span class="ident">make_x_index</span></span>(<span>self, force_rerun_xlims: bool = False, force_rerun_freqdet: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_x_index(self, 
                 force_rerun_xlims: bool = False,
                 force_rerun_freqdet: bool = False):
    &#34;&#34;&#34;Make the DateTime Index for the series using the start and end dates scraped from the tooltips. 
    This uses Selenium and also scrapes the some of the latest datapoints from the tooltips on the chart in order to determine
    the frequency of the time series. It will take a bit of time to run.

    **Parameters:**
    - force_rerun_xlims (bool): Whether to force a rerun of the method to get the start and end dates and frequency of the time series again. The method
    will not run again by default if done a second time and start_end and frequency attributes are already set. 
    - force_rerun_freqdet (bool): Whether to force a rerun of the method to get the frequency of the time series again. The method
    will not run again by default if done a second time and frequency attribute is already set. 
    &#34;&#34;&#34;
    ## Update chart...
    self.update_chart()

    if not hasattr(self, &#34;tooltip_scraper&#34;):  # If the tooltip scraper object is not already created, create it.
        self.tooltip_scraper = utils.TooltipScraper(parent_instance = self) # Create a tooltip scraper child object

    print(&#34;Using selenium and tooltip scraping to construct the date time index for the time-series, this&#39;ll take a bit...&#34;)
    if force_rerun_xlims or not hasattr(self, &#34;start_end&#34;):
        self.get_xlims_from_tooltips()
    # Get the first and last datapoints from the chart at MAX datespan

    if self.start_end is not None:
        logger.info(f&#34;Start and end values scraped from tooltips: \n{self.start_end}&#34;)
    else:
        print(&#34;Error: Start and end values not found...pulling out....&#34;)
        logger.debug(f&#34;Error: Start and end values not found...pulling out....&#34;)
        return None
    
    ## Get the latest 10 or so points from the chart, date and value from tooltips, in order to determine the frequency of the time series.
    if force_rerun_freqdet or not hasattr(self, &#34;latest_points&#34;):
        datapoints = self.tooltip_scraper.get_latest_points(num_points = 5)  # Get the latest 10 points from the chart.
        self.latest_points = datapoints
        latest_dates = [datapoint[&#34;date&#34;] for datapoint in datapoints]
        print(&#34;Latest dates: &#34;, latest_dates)

        ## Get the frequency of the time series
        self.date_series = pd.Series(latest_dates[::-1]).astype(&#34;datetime64[ns]&#34;)
        self.frequency = utils.get_date_frequency(self.date_series)
    print(&#34;Frequency of time-series: &#34;, self.frequency)

    start_date = self.start_end[&#34;start_date&#34;]; end_date = self.start_end[&#34;end_date&#34;]
    dtIndex = self.dtIndex(start_date=start_date, end_date=end_date, ser_name=self.series_name)
    if dtIndex is not None:
        logger.info(f&#34;DateTimeIndex created successfully for the time-series.&#34;)
        self.x_index = dtIndex
        return dtIndex  
    else:
        logger.info(f&#34;Error creating DateTimeIndex for the time-series.&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Make the DateTime Index for the series using the start and end dates scraped from the tooltips.
This uses Selenium and also scrapes the some of the latest datapoints from the tooltips on the chart in order to determine
the frequency of the time series. It will take a bit of time to run.</p>
<p><strong>Parameters:</strong>
- force_rerun_xlims (bool): Whether to force a rerun of the method to get the start and end dates and frequency of the time series again. The method
will not run again by default if done a second time and start_end and frequency attributes are already set.
- force_rerun_freqdet (bool): Whether to force a rerun of the method to get the frequency of the time series again. The method
will not run again by default if done a second time and frequency attribute is already set.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.plot_series"><code class="name flex">
<span>def <span class="ident">plot_series</span></span>(<span>self,<br>series: pandas.core.series.Series = None,<br>annotation_text: str = None,<br>dpi: int = 300,<br>ann_box_pos: tuple = (0, -0.2))</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_series(self, series: pd.Series = None, 
                annotation_text: str = None, 
                dpi: int = 300, 
                ann_box_pos: tuple = (0, - 0.2)):
    &#34;&#34;&#34;
    Plots the time series data using pandas with plotly as the backend. Plotly is set as the pandas backend in __init__.py for tedata.
    If you want to use matplotlib or other plotting library don&#39;t use this method, plot the series attribute data directly. If using jupyter
    you can set 

    **Parameters**
    - series (pd.Series): The series to plot. Default is None. If None, the series attribute of the class will be plotted.
    - annotation_text (str): Text to display in the annotation box at the bottom of the chart. Default is None. If None, the default annotation text
    will be created from the metadata.
    - dpi (int): The resolution of the plot in dots per inch. Default is 300.
    - ann_box_pos (tuple): The position of the annotation box on the chart. Default is (0, -0.23) which is bottom left.

    **Returns** None
    &#34;&#34;&#34;
    
    if series is None:
        series = self.series

    fig = series.plot()  # Plot the series using pandas, plotly needs to be set as the pandas plotting backend.

     # Existing title and label logic
    if hasattr(self, &#34;series_metadata&#34;):
        title = str(self.series_metadata[&#34;country&#34;]).capitalize() + &#34;: &#34; + str(self.series_metadata[&#34;title&#34;]).capitalize()
        ylabel = str(self.series_metadata[&#34;units&#34;]).capitalize()
        
        # Create default annotation text from metadata
        if annotation_text is None:
            annotation_text = (
                f&#34;Source: {self.series_metadata[&#39;source&#39;]}&lt;br&gt;&#34;
                f&#34;Original Source: {self.series_metadata[&#39;original_source&#39;]}&lt;br&gt;&#34;
                f&#34;Frequency: {self.series_metadata[&#39;frequency&#39;]}&#34;
            )
    else:
        title = &#34;Time Series Plot&#34;
        ylabel = &#34;Value&#34;
        annotation_text = annotation_text or &#34;Source: Trading Economics&#34;

    # Add text annotation to bottom left
    fig.add_annotation(
        text=annotation_text,
        xref=&#34;paper&#34;, yref=&#34;paper&#34;,
        x=ann_box_pos[0], y=ann_box_pos[1],
        showarrow=False, font=dict(size=10),
        align=&#34;left&#34;,  xanchor=&#34;left&#34;,
        yanchor=&#34;bottom&#34;, bgcolor=&#34;rgba(255, 255, 255, 0.8)&#34;,
        bordercolor=&#34;black&#34;, borderwidth=1)

    # Label x and y axis
    fig.update_layout(
        legend=dict(
        title_text=&#34;&#34;,  # Remove legend title
        orientation=&#34;h&#34;,
        yanchor=&#34;bottom&#34;,
        y=-0.2,  # Adjust this value to move the legend further down
        xanchor=&#34;center&#34;,
        x=0.5
        ),
        yaxis_title=ylabel,
        xaxis_title=&#34;&#34;,
        title = title)

    # Show the figure
    fig.show()
    self.plot = fig</code></pre>
</details>
<div class="desc"><p>Plots the time series data using pandas with plotly as the backend. Plotly is set as the pandas backend in <strong>init</strong>.py for tedata.
If you want to use matplotlib or other plotting library don't use this method, plot the series attribute data directly. If using jupyter
you can set </p>
<p><strong>Parameters</strong>
- series (pd.Series): The series to plot. Default is None. If None, the series attribute of the class will be plotted.
- annotation_text (str): Text to display in the annotation box at the bottom of the chart. Default is None. If None, the default annotation text
will be created from the metadata.
- dpi (int): The resolution of the plot in dots per inch. Default is 300.
- ann_box_pos (tuple): The position of the annotation box on the chart. Default is (0, -0.23) which is bottom left.</p>
<p><strong>Returns</strong> None</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.save_plot"><code class="name flex">
<span>def <span class="ident">save_plot</span></span>(<span>self,<br>filename: str = 'plot',<br>save_path: str = '/Users/jamesbishop/Documents/Python/Scraping/tedata',<br>dpi: int = 300,<br>format: str = 'png')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_plot(self, filename: str = &#34;plot&#34;, save_path: str = os.getcwd(), dpi: int = 300, format: str = &#34;png&#34;):
    &#34;&#34;&#34;Save the plot to a file. The plot must be created using the plot_series method. This method will save the plot as a PNG image file.

    **Parameters**
    - filename (str): The name of the file to save the plot to. Default is &#39;plot.png&#39;.
    - save_path (str): The directory to save the plot to. Default is the current working directory.
    - dpi (int): The resolution of the plot in dots per inch. Default is 300.
    - format (str): The format to save the plot in. Default is &#39;png&#39;. Other options are: &#34;html&#34;, &#34;bmp&#34;, &#34;jpeg&#34;, &#34;jpg&#34;.
    Use &#34;html&#34; to save as an interactive plotly plot.

    :Returns: None
    &#34;&#34;&#34;

    if hasattr(self, &#34;plot&#34;):
        if format == &#34;html&#34;:
            self.plot.write_html(f&#34;{save_path}{fdel}{filename}.html&#34;)
            logger.info(f&#34;Plot saved as {save_path}{fdel}{filename}.html&#34;)
        else:
            self.plot.write_image(f&#34;{save_path}{fdel}{filename}.{format}&#34;, format=format, scale=dpi/100, width = 1400, height = 500)
            logger.info(f&#34;Plot saved as {filename}&#34;)
    else:
        print(&#34;Error: Plot not found. Run plot_series() method to create a plot.&#34;)
        logger.debug(&#34;Error: Plot not found. Run plot_series() method to create a plot.&#34;)</code></pre>
</details>
<div class="desc"><p>Save the plot to a file. The plot must be created using the plot_series method. This method will save the plot as a PNG image file.</p>
<p><strong>Parameters</strong>
- filename (str): The name of the file to save the plot to. Default is 'plot.png'.
- save_path (str): The directory to save the plot to. Default is the current working directory.
- dpi (int): The resolution of the plot in dots per inch. Default is 300.
- format (str): The format to save the plot in. Default is 'png'. Other options are: "html", "bmp", "jpeg", "jpg".
Use "html" to save as an interactive plotly plot.</p>
<p>:Returns: None</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.scale_series"><code class="name flex">
<span>def <span class="ident">scale_series</span></span>(<span>self, right_way_up: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale_series(self, right_way_up: bool = True):
    &#34;&#34;&#34;Scale the series using the first and last values from the series pulled from the tooltip box. Uses the y axis limits and the max and min of the y axis
    to determine the scaling factor to convert pixel co-ordinates to data values. The scaling factor is stored in the self.axlims_upp attribute.&#34;&#34;&#34;

    if not right_way_up:
        max_val = self.y_axis.index.max()  # This should be the top pixel of the chart.
        self.series = utils.invert_series(self.series, max_val = max_val)

    if hasattr(self, &#34;start_end&#34;):
        y0 = self.start_end[&#34;start_value&#34;]; y1 = self.start_end[&#34;end_value&#34;]
        pix0 = self.series.iloc[0]; pix1 = self.series.iloc[-1]
        
        self.unit_per_px_alt = abs(y1 - y0) / abs(pix1 - pix0)  # Calculated from the start and end datapoints.
        
        if not hasattr(self, &#34;axis_limits&#34;):
            self.axis_limits = self.extract_axis_limits()
        ## Turns out that this formulation below is the best way to calculate the scaling factor for the chart.
        self.axlims_upp = (self.y_axis.iloc[-1] - self.y_axis.iloc[0]) / (self.axis_limits[&#34;y_max&#34;] - self.axis_limits[&#34;y_min&#34;])

        # if the start and end points are at similar values this will be problematic though. 
        logger.debug(&#34;Scale series method: &#34;
                    f&#34;Start value, end value: {y0}, {y1}, pix0, pix1: {pix0}, {pix1}, &#34;
                     f&#34;data units per chart pixel from start &amp; end points: {self.unit_per_px_alt}, &#34;
                     f&#34;unit_per_pix calculated from the y axis ticks: {self.unit_per_pix}, &#34;
                     f&#34;inverse of that: {1/self.unit_per_pix}, &#34;
                     f&#34;unit_per_pix from axis limits and self.y_axis (probably best way): {self.axlims_upp}&#34;)

        self.unscaled_series = self.series.copy()
        ##Does the Y axis cross zero? Where is the zero point??
        x_intercept = utils.find_zero_crossing(self.series)

        if x_intercept:
            logger.debug(f&#34;Y axis Series does cross zero at:  {x_intercept}&#34;)
            pix0 = x_intercept

        for i in range(len(self.series)):
            self.series.iloc[i] = (self.series.iloc[i] - pix0)*self.axlims_upp + y0

        self.series = self.series
    else:
        print(&#34;start_end not found, run get_datamax_min() first.&#34;)
        logger.debug(&#34;start_end not found, run get_datamax_min() first.&#34;)
        return

    return self.series</code></pre>
</details>
<div class="desc"><p>Scale the series using the first and last values from the series pulled from the tooltip box. Uses the y axis limits and the max and min of the y axis
to determine the scaling factor to convert pixel co-ordinates to data values. The scaling factor is stored in the self.axlims_upp attribute.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.scrape_metadata"><code class="name flex">
<span>def <span class="ident">scrape_metadata</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrape_metadata(self):
    &#34;&#34;&#34;Scrape metadata from the page. This method scrapes metadata from the page and stores it in the &#39;metadata&#39; attribute. The metadata
    includes the title, indicator, country, length, frequency, source, , original source, id, start date, end date, min value, and max value of the series.
    It also scrapes a description of the series if available and stores it in the &#39;description&#39; attribute.
    &#34;&#34;&#34;

    self.metadata = {}
    logger.debug(f&#34;Scraping metadata for the series from the page...&#34;)

    try:
        self.metadata[&#34;units&#34;] = self.chart_soup.select_one(&#39;#singleIndChartUnit2&#39;).text
    except Exception as e:
        print(&#34;Units label not found: &#34;, {str(e)})
        self.metadata[&#34;units&#34;] = &#34;a.u&#34;
    
    try:
        self.metadata[&#34;original_source&#34;] = self.chart_soup.select_one(&#39;#singleIndChartUnit&#39;).text
    except Exception as e:
        print(&#34;original_source label not found: &#34;, {str(e)})
        self.metadata[&#34;original_source&#34;] = &#34;unknown&#34;

    if hasattr(self, &#34;series&#34;):
        if hasattr(self, &#34;page_soup&#34;):
            heads = self.page_soup.select(&#34;#ctl00_Head1&#34;)
            self.metadata[&#34;title&#34;] = heads[0].title.text.strip()
        else:
            self.metadata[&#34;title&#34;] = self.last_url.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;)  # Use URL if can&#39;t find the title
        self.metadata[&#34;indicator&#34;] = self.last_url.split(&#34;/&#34;)[-1].replace(&#34;-&#34;, &#34; &#34;)  
        self.metadata[&#34;country&#34;] = self.last_url.split(&#34;/&#34;)[-2].replace(&#34;-&#34;, &#34; &#34;) 
        self.metadata[&#34;length&#34;] = len(self.series)
        self.metadata[&#34;frequency&#34;] = self.frequency  
        self.metadata[&#34;source&#34;] = &#34;Trading Economics&#34; 
        self.metadata[&#34;id&#34;] = &#34;/&#34;.join(self.last_url.split(&#34;/&#34;)[-2:])
        self.metadata[&#34;start_date&#34;] = self.series.index[0].strftime(&#34;%Y-%m-%d&#34;)
        self.metadata[&#34;end_date&#34;] = self.series.index[-1].strftime(&#34;%Y-%m-%d&#34;)
        self.metadata[&#34;min_value&#34;] = float(self.series.min())
        self.metadata[&#34;max_value&#34;] = float(self.series.max())
        logger.info(f&#34;\nSeries metadata: \n {self.metadata}&#34;)

    try:
        desc_card = self.page_soup.select_one(&#34;#item_definition&#34;)
        header_text = desc_card.select_one(&#39;.card-header&#39;).text.strip()
        if header_text.lower() == self.metadata[&#34;title&#34;].lower():
            self.metadata[&#34;description&#34;] = desc_card.select_one(&#39;.card-body&#39;).text.strip()
        else:
            print(&#34;Description card title does not match series title.&#34;)
            self.metadata[&#34;description&#34;] = &#34;Description not found.&#34;
    except Exception as e:
        print(&#34;Description card not found: &#34;, {str(e)})

    self.series_metadata = pd.Series(self.metadata)
    if self.metadata is not None:
        logger.debug(f&#34;Metadata scraped successfully: {self.metadata}&#34;)</code></pre>
</details>
<div class="desc"><p>Scrape metadata from the page. This method scrapes metadata from the page and stores it in the 'metadata' attribute. The metadata
includes the title, indicator, country, length, frequency, source, , original source, id, start date, end date, min value, and max value of the series.
It also scrapes a description of the series if available and stores it in the 'description' attribute.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.select_chart_type"><code class="name flex">
<span>def <span class="ident">select_chart_type</span></span>(<span>self, chart_type: str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_chart_type(self, chart_type: str):
    &#34;&#34;&#34;Select a chart type on the Trading Economics chart. This is done by clicking the chart type button and then selecting the specified chart type.
    The chart type should be a string that matches one of the chart types in the chart_types dictionary. The method will click the chart type button
    and then select the specified chart type. It will also update the chart_type attribute of the class to reflect the new chart type.

    **Parameters:**
    - chart_type (str): The chart type to select on the chart. This must be one of the keys of the chart_types dictionary attribute of the class.
    List the options by printing self.chart_types.keys()
    &#34;&#34;&#34;
    if not hasattr(self, &#34;chart_types&#34;):
        self.create_chart_types_dict()

    if chart_type in self.chart_types.keys():
        if self.click_button(&#34;#chart &gt; div &gt; div &gt; div.hawk-header &gt; div &gt; div.pickChartTypes &gt; div &gt; button&#34;):
            self.click_button(self.chart_types[chart_type])
            self.chart_type = self.expected_types[chart_type]
            logger.info(f&#34;Chart type set to: {chart_type}&#34;)
            self.update_chart()
            return True
        else:
            logger.debug(f&#34;Error selecting chart type: {chart_type}&#34;)
            return False
    else:
        logger.debug(f&#34;Chart type not found: {chart_type}&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Select a chart type on the Trading Economics chart. This is done by clicking the chart type button and then selecting the specified chart type.
The chart type should be a string that matches one of the chart types in the chart_types dictionary. The method will click the chart type button
and then select the specified chart type. It will also update the chart_type attribute of the class to reflect the new chart type.</p>
<p><strong>Parameters:</strong>
- chart_type (str): The chart type to select on the chart. This must be one of the keys of the chart_types dictionary attribute of the class.
List the options by printing self.chart_types.keys()</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.select_line_chart"><code class="name flex">
<span>def <span class="ident">select_line_chart</span></span>(<span>self, update_chart: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_line_chart(self, update_chart: bool = False):
    &#34;&#34;&#34;Select the line chart type on the Trading Economics chart. This is done by clicking the chart type button and then selecting the line chart type.&#34;&#34;&#34;

    if update_chart:
        self.update_chart()
    if not hasattr(self, &#34;chart_types&#34;):
        self.create_chart_types_dict()

    if self.click_button(&#34;#chart &gt; div &gt; div &gt; div.hawk-header &gt; div &gt; div.pickChartTypes &gt; div &gt; button&#34;):
        if self.click_button(self.chart_types[&#34;Line&#34;]):
            self.chart_type = &#34;lineChart&#34;
            logger.info(&#34;Line chart type selected.&#34;)
            self.update_chart()
            return True
    else:
        print(&#34;Error selecting line chart type.&#34;)
        logger.debug(&#34;Error selecting line chart type.&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Select the line chart type on the Trading Economics chart. This is done by clicking the chart type button and then selecting the line chart type.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.series_from_chart_soup"><code class="name flex">
<span>def <span class="ident">series_from_chart_soup</span></span>(<span>self,<br>selector: str = '.highcharts-tracker-line',<br>invert_the_series: bool = True,<br>set_max_datespan: bool = False,<br>local_run: bool = False,<br>use_chart_type: Literal['Line', 'Spline'] = 'Spline')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def series_from_chart_soup(self, selector: str = &#34;.highcharts-tracker-line&#34;, 
                           invert_the_series: bool = True, 
                           set_max_datespan: bool = False,
                           local_run: bool = False,
                           use_chart_type: Literal[&#34;Line&#34;, &#34;Spline&#34;] = &#34;Spline&#34;):  
      
    &#34;&#34;&#34;Extract series data from element text. This extracts the plotted series from the svg chart by taking the PATH 
    element of the data tarace on the chart. Series values are pixel co-ordinates on the chart.

    **Parameters:**
    - invert_the_series (bool): Whether to invert the series values.
    - return_series (bool): whether or not to return the series at end. Series is assigned to self.series always.
    - set_max_datespan (bool): Whether to set the date span to MAX before extracting the series data. Default is False.
    - local_run (bool): Whether the method is being run to get the full date_span series or just extacting part of the series
    to then aggregate together the full series. Default is False.
    - use_chart_type (str): The chart type to use for the extraction of the series data. Default is &#34;Spline&#34;. This is used to set the chart type before extracting the series data.
    CUATION: This method may fail with certain types of charts. It is best to use Spline unless you have a reason to use another type.

    **Returns:**

    - series (pd.Series): The extracted series data that is the raw pixel co-ordinate values of the data trace on the svg chart.
    &#34;&#34;&#34;

    self.update_chart() # Update chart..

    self.select_chart_type(use_chart_type) ## Use a certain chart type for the extraction of the series data. May fail with certain types of charts.

    if set_max_datespan and self.date_span != &#34;MAX&#34;:
        self.set_date_span(&#34;MAX&#34;)
    logger.info(f&#34;Series path extraction method: Extracting series data from chart soup.&#34;) 
    logger.info(f&#34;Date span: {self.date_span}. Chart type: {self.chart_type}, URL: {self.last_url}.&#34;)

    datastrlist = self.chart_soup.select(selector)
    
    if len(datastrlist) &gt; 1:
        print(&#34;Multiple series found in the chart. Got to figure out which one to use... work to do here... This will not work yet, please report error.&#34;)
        raise ValueError(&#34;Multiple series found in the chart. Got to figure out which one to use... work to do here...&#34;)
    else:
        raw_series = self.chart_soup.select_one(&#34;.highcharts-graph&#34;)[&#34;d&#34;].split(&#34; &#34;)

    ser = pd.Series(raw_series)
    ser_num = pd.to_numeric(ser, errors=&#39;coerce&#39;).dropna()

    exvals = ser_num[::2]; yvals = ser_num[1::2]
    exvals = exvals.sort_values().to_list()
    yvals = yvals.to_list()
    series = pd.Series(yvals, index = exvals, name = &#34;Extracted Series&#34;)

    if local_run:
        y_axis = self.get_y_axis()
    else:
        y_axis = self.y_axis

    if invert_the_series:
        series = utils.invert_series(series, max_val = y_axis.index.max())
    
    if not local_run:
        self.trace_path_series_raw = series.copy()
     # Keep the raw pixel co-ordinate valued series extracted from the svg path element.
    logger.debug(f&#34;Raw data series extracted successfully: {series.head(2)}&#34;)
    self.series_extracted_from = use_chart_type  #Add this attribute so that the apply_x_index method knows which chart_type the series came from.
    self.series = series
    return series</code></pre>
</details>
<div class="desc"><p>Extract series data from element text. This extracts the plotted series from the svg chart by taking the PATH
element of the data tarace on the chart. Series values are pixel co-ordinates on the chart.</p>
<p><strong>Parameters:</strong>
- invert_the_series (bool): Whether to invert the series values.
- return_series (bool): whether or not to return the series at end. Series is assigned to self.series always.
- set_max_datespan (bool): Whether to set the date span to MAX before extracting the series data. Default is False.
- local_run (bool): Whether the method is being run to get the full date_span series or just extacting part of the series
to then aggregate together the full series. Default is False.
- use_chart_type (str): The chart type to use for the extraction of the series data. Default is "Spline". This is used to set the chart type before extracting the series data.
CUATION: This method may fail with certain types of charts. It is best to use Spline unless you have a reason to use another type.</p>
<p><strong>Returns:</strong></p>
<ul>
<li>series (pd.Series): The extracted series data that is the raw pixel co-ordinate values of the data trace on the svg chart.</li>
</ul></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.set_date_span"><code class="name flex">
<span>def <span class="ident">set_date_span</span></span>(<span>self, date_span: str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_date_span(self, date_span: str):
    &#34;&#34;&#34;Set the date span on the Trading Economics chart. This is done by clicking the date span button on the chart. The date span is a button on the chart
    that allows you to change the date range of the chart. This method will click the button for the date span specified in the date_span parameter.
    The date_span parameter should be a string that matches one of the date span buttons on the chart. The method will also update the date_span attribute
    of the class to reflect the new date span.&#34;&#34;&#34;
    if not hasattr(self, &#34;date_spans&#34;):
        self.determine_date_span()
    if date_span in self.date_spans.keys():
        if self.click_button(self.date_spans[date_span]):
            self.date_span = date_span
            logger.info(f&#34;Date span set to: {date_span}&#34;)
            self.update_chart()
            return True
        else:
            logger.info(f&#34;Error setting date span: {date_span}, check that the date span button is clickable.&#34;)
            return False
    else:
        logger.info(f&#34;Error setting date span: {date_span}, check that the supplied date span matches one of the keys in the self.date_spans attribute (dict).&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Set the date span on the Trading Economics chart. This is done by clicking the date span button on the chart. The date span is a button on the chart
that allows you to change the date range of the chart. This method will click the button for the date span specified in the date_span parameter.
The date_span parameter should be a string that matches one of the date span buttons on the chart. The method will also update the date_span attribute
of the class to reflect the new date span.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.update_chart"><code class="name flex">
<span>def <span class="ident">update_chart</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_chart(self):
    &#34;&#34;&#34;Update the chart attributes after loading a new page or clicking a button. This will check the page source and update the 
    beautiful soup objects such as chart_soup, from which most other methods derive their functionality. It will also update the full_chart attribute
    which is the full HTML of the chart element on the page. This method should be run after changing something on the webpage via driver such
    as clicking a button to change the date span or chart type.&#34;&#34;&#34;

    try:
        # Since we inherit from SharedWebDriverState, we can directly set the page_source property
        self.page_source = self.driver.page_source
        return True

    except Exception as e:
        logger.error(f&#34;Failed to update chart: {e}&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Update the chart attributes after loading a new page or clicking a button. This will check the page source and update the
beautiful soup objects such as chart_soup, from which most other methods derive their functionality. It will also update the full_chart attribute
which is the full HTML of the chart element on the page. This method should be run after changing something on the webpage via driver such
as clicking a button to change the date span or chart type.</p></div>
</dd>
<dt id="tedata.scraper.TE_Scraper.update_date_span"><code class="name flex">
<span>def <span class="ident">update_date_span</span></span>(<span>self, update_chart: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_date_span(self, update_chart: bool = False):
    &#34;&#34;&#34;Update the date span after clicking a button. This will check the page source and update the date span attribute.
    This method can be used t check that the curret date span is correct after clicking a button to change it. 
    It will update the date_span attribute. It is not necessary after running set_date_span though as that method already updates the date span attribute.

    **Parameters:**
    - update_chart (bool): Whether to update the chart before determining the date span. Default is False.
    &#34;&#34;&#34;

    if update_chart:
        self.update_chart()
    self.date_span_dict = self.determine_date_span()
    self.date_span = list(self.date_span_dict.keys())[0]</code></pre>
</details>
<div class="desc"><p>Update the date span after clicking a button. This will check the page source and update the date span attribute.
This method can be used t check that the curret date span is correct after clicking a button to change it.
It will update the date_span attribute. It is not necessary after running set_date_span though as that method already updates the date span attribute.</p>
<p><strong>Parameters:</strong>
- update_chart (bool): Whether to update the chart before determining the date span. Default is False.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tedata" href="index.html">tedata</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tedata.scraper.find_element_header_match" href="#tedata.scraper.find_element_header_match">find_element_header_match</a></code></li>
<li><code><a title="tedata.scraper.scrape_chart" href="#tedata.scraper.scrape_chart">scrape_chart</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tedata.scraper.TE_Scraper" href="#tedata.scraper.TE_Scraper">TE_Scraper</a></code></h4>
<ul class="">
<li><code><a title="tedata.scraper.TE_Scraper.BrowserType" href="#tedata.scraper.TE_Scraper.BrowserType">BrowserType</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.apply_x_index" href="#tedata.scraper.TE_Scraper.apply_x_index">apply_x_index</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.click_button" href="#tedata.scraper.TE_Scraper.click_button">click_button</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.click_max_button" href="#tedata.scraper.TE_Scraper.click_max_button">click_max_button</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.close" href="#tedata.scraper.TE_Scraper.close">close</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.create_chart_types_dict" href="#tedata.scraper.TE_Scraper.create_chart_types_dict">create_chart_types_dict</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.custom_date_span" href="#tedata.scraper.TE_Scraper.custom_date_span">custom_date_span</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.determine_date_span" href="#tedata.scraper.TE_Scraper.determine_date_span">determine_date_span</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.dtIndex" href="#tedata.scraper.TE_Scraper.dtIndex">dtIndex</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.extract_axis_limits" href="#tedata.scraper.TE_Scraper.extract_axis_limits">extract_axis_limits</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.find_max_button" href="#tedata.scraper.TE_Scraper.find_max_button">find_max_button</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.get_datamax_min" href="#tedata.scraper.TE_Scraper.get_datamax_min">get_datamax_min</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.get_element" href="#tedata.scraper.TE_Scraper.get_element">get_element</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.get_page_source" href="#tedata.scraper.TE_Scraper.get_page_source">get_page_source</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.get_xlims_from_tooltips" href="#tedata.scraper.TE_Scraper.get_xlims_from_tooltips">get_xlims_from_tooltips</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.get_y_axis" href="#tedata.scraper.TE_Scraper.get_y_axis">get_y_axis</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.load_page" href="#tedata.scraper.TE_Scraper.load_page">load_page</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.make_x_index" href="#tedata.scraper.TE_Scraper.make_x_index">make_x_index</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.plot_series" href="#tedata.scraper.TE_Scraper.plot_series">plot_series</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.save_plot" href="#tedata.scraper.TE_Scraper.save_plot">save_plot</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.scale_series" href="#tedata.scraper.TE_Scraper.scale_series">scale_series</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.scrape_metadata" href="#tedata.scraper.TE_Scraper.scrape_metadata">scrape_metadata</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.select_chart_type" href="#tedata.scraper.TE_Scraper.select_chart_type">select_chart_type</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.select_line_chart" href="#tedata.scraper.TE_Scraper.select_line_chart">select_line_chart</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.series_from_chart_soup" href="#tedata.scraper.TE_Scraper.series_from_chart_soup">series_from_chart_soup</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.set_date_span" href="#tedata.scraper.TE_Scraper.set_date_span">set_date_span</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.update_chart" href="#tedata.scraper.TE_Scraper.update_chart">update_chart</a></code></li>
<li><code><a title="tedata.scraper.TE_Scraper.update_date_span" href="#tedata.scraper.TE_Scraper.update_date_span">update_date_span</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.5</a>.</p>
</footer>
</body>
</html>
